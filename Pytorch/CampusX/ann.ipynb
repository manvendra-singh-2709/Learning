{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ad3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f91436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11a058370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2716e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available.\n",
      "Using MPS: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available.\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"MPS available.\")\n",
    "    print(f\"Using MPS: {torch.mps.device_count()}\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_device(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335479a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fmnist_small.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c8f272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['id', 'Unnamed: 32'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bab7902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73649148",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train).to(dtype=torch.float32, device=device)\n",
    "x_test_tensor = torch.from_numpy(x_test).to(dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.from_numpy(y_train).to(dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.from_numpy(y_test).to(dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "016eb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, feartures, labels):\n",
    "        self.features = feartures\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e03118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CancerDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(x_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7328232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78e19dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=3, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=3, out_features=1, device=device),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2569fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(x_train_tensor.shape[1])\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab4d1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6178330183029175\n",
      "Epoch: 2, Loss: 0.5962808728218079\n",
      "Epoch: 3, Loss: 0.6785789132118225\n",
      "Epoch: 4, Loss: 0.6505520939826965\n",
      "Epoch: 5, Loss: 0.6888703107833862\n",
      "Epoch: 6, Loss: 0.7066325545310974\n",
      "Epoch: 7, Loss: 0.6415525078773499\n",
      "Epoch: 8, Loss: 0.639633059501648\n",
      "Epoch: 9, Loss: 0.7033472061157227\n",
      "Epoch: 10, Loss: 0.7057944536209106\n",
      "Epoch: 11, Loss: 0.6513578295707703\n",
      "Epoch: 12, Loss: 0.6787814497947693\n",
      "Epoch: 13, Loss: 0.645814061164856\n",
      "Epoch: 14, Loss: 0.7108530402183533\n",
      "Epoch: 15, Loss: 0.6646132469177246\n",
      "Epoch: 16, Loss: 0.6916759610176086\n",
      "Epoch: 17, Loss: 0.630558431148529\n",
      "Epoch: 18, Loss: 0.614026665687561\n",
      "Epoch: 19, Loss: 0.6813562512397766\n",
      "Epoch: 20, Loss: 0.6561017632484436\n",
      "Epoch: 21, Loss: 0.7056004405021667\n",
      "Epoch: 22, Loss: 0.6673980355262756\n",
      "Epoch: 23, Loss: 0.6674953103065491\n",
      "Epoch: 24, Loss: 0.6532295942306519\n",
      "Epoch: 25, Loss: 0.6856598258018494\n",
      "Epoch: 26, Loss: 0.6778575778007507\n",
      "Epoch: 27, Loss: 0.6821116209030151\n",
      "Epoch: 28, Loss: 0.6642427444458008\n",
      "Epoch: 29, Loss: 0.6822977662086487\n",
      "Epoch: 30, Loss: 0.7147560715675354\n",
      "Epoch: 31, Loss: 0.6725096702575684\n",
      "Epoch: 32, Loss: 0.7014134526252747\n",
      "Epoch: 33, Loss: 0.6195107102394104\n",
      "Epoch: 34, Loss: 0.621854305267334\n",
      "Epoch: 35, Loss: 0.6831583380699158\n",
      "Epoch: 36, Loss: 0.6953253149986267\n",
      "Epoch: 37, Loss: 0.6773786544799805\n",
      "Epoch: 38, Loss: 0.6491602063179016\n",
      "Epoch: 39, Loss: 0.6393702626228333\n",
      "Epoch: 40, Loss: 0.6898877024650574\n",
      "Epoch: 41, Loss: 0.6434965133666992\n",
      "Epoch: 42, Loss: 0.6471033096313477\n",
      "Epoch: 43, Loss: 0.6834214925765991\n",
      "Epoch: 44, Loss: 0.6831139922142029\n",
      "Epoch: 45, Loss: 0.6878352761268616\n",
      "Epoch: 46, Loss: 0.6860769987106323\n",
      "Epoch: 47, Loss: 0.6694691777229309\n",
      "Epoch: 48, Loss: 0.6200627088546753\n",
      "Epoch: 49, Loss: 0.6287790536880493\n",
      "Epoch: 50, Loss: 0.6813658475875854\n",
      "Epoch: 51, Loss: 0.7088960409164429\n",
      "Epoch: 52, Loss: 0.6353951692581177\n",
      "Epoch: 53, Loss: 0.6481881141662598\n",
      "Epoch: 54, Loss: 0.6813734173774719\n",
      "Epoch: 55, Loss: 0.6366961598396301\n",
      "Epoch: 56, Loss: 0.6373797059059143\n",
      "Epoch: 57, Loss: 0.7087364196777344\n",
      "Epoch: 58, Loss: 0.6599587798118591\n",
      "Epoch: 59, Loss: 0.6333884596824646\n",
      "Epoch: 60, Loss: 0.6669151186943054\n",
      "Epoch: 61, Loss: 0.6505102515220642\n",
      "Epoch: 62, Loss: 0.7153862714767456\n",
      "Epoch: 63, Loss: 0.6756919026374817\n",
      "Epoch: 64, Loss: 0.6620444655418396\n",
      "Epoch: 65, Loss: 0.6797662973403931\n",
      "Epoch: 66, Loss: 0.7190877795219421\n",
      "Epoch: 67, Loss: 0.6838474869728088\n",
      "Epoch: 68, Loss: 0.658696174621582\n",
      "Epoch: 69, Loss: 0.5514193177223206\n",
      "Epoch: 70, Loss: 0.6631349325180054\n",
      "Epoch: 71, Loss: 0.6338484883308411\n",
      "Epoch: 72, Loss: 0.6657691597938538\n",
      "Epoch: 73, Loss: 0.6960731744766235\n",
      "Epoch: 74, Loss: 0.6960046887397766\n",
      "Epoch: 75, Loss: 0.6519567370414734\n",
      "Epoch: 76, Loss: 0.6451873779296875\n",
      "Epoch: 77, Loss: 0.5915012359619141\n",
      "Epoch: 78, Loss: 0.6672765612602234\n",
      "Epoch: 79, Loss: 0.6651471853256226\n",
      "Epoch: 80, Loss: 0.6765257716178894\n",
      "Epoch: 81, Loss: 0.6699165105819702\n",
      "Epoch: 82, Loss: 0.6257165670394897\n",
      "Epoch: 83, Loss: 0.6671503782272339\n",
      "Epoch: 84, Loss: 0.6742598414421082\n",
      "Epoch: 85, Loss: 0.6631141901016235\n",
      "Epoch: 86, Loss: 0.6634258031845093\n",
      "Epoch: 87, Loss: 0.6424135565757751\n",
      "Epoch: 88, Loss: 0.678500771522522\n",
      "Epoch: 89, Loss: 0.6513617634773254\n",
      "Epoch: 90, Loss: 0.649753749370575\n",
      "Epoch: 91, Loss: 0.6645406484603882\n",
      "Epoch: 92, Loss: 0.6475375294685364\n",
      "Epoch: 93, Loss: 0.6373258233070374\n",
      "Epoch: 94, Loss: 0.691161572933197\n",
      "Epoch: 95, Loss: 0.6427713632583618\n",
      "Epoch: 96, Loss: 0.5801339149475098\n",
      "Epoch: 97, Loss: 0.6344536542892456\n",
      "Epoch: 98, Loss: 0.6697222590446472\n",
      "Epoch: 99, Loss: 0.6740497350692749\n",
      "Epoch: 100, Loss: 0.654542088508606\n",
      "Epoch: 101, Loss: 0.6593155264854431\n",
      "Epoch: 102, Loss: 0.6649337410926819\n",
      "Epoch: 103, Loss: 0.6887482404708862\n",
      "Epoch: 104, Loss: 0.695224404335022\n",
      "Epoch: 105, Loss: 0.6771370768547058\n",
      "Epoch: 106, Loss: 0.64960777759552\n",
      "Epoch: 107, Loss: 0.6652376055717468\n",
      "Epoch: 108, Loss: 0.5952986478805542\n",
      "Epoch: 109, Loss: 0.6608749628067017\n",
      "Epoch: 110, Loss: 0.6255692839622498\n",
      "Epoch: 111, Loss: 0.6716668009757996\n",
      "Epoch: 112, Loss: 0.7272198796272278\n",
      "Epoch: 113, Loss: 0.6881929039955139\n",
      "Epoch: 114, Loss: 0.69942706823349\n",
      "Epoch: 115, Loss: 0.6166775822639465\n",
      "Epoch: 116, Loss: 0.695595920085907\n",
      "Epoch: 117, Loss: 0.6973766684532166\n",
      "Epoch: 118, Loss: 0.638778805732727\n",
      "Epoch: 119, Loss: 0.6775236129760742\n",
      "Epoch: 120, Loss: 0.6867457628250122\n",
      "Epoch: 121, Loss: 0.6493730545043945\n",
      "Epoch: 122, Loss: 0.6678927540779114\n",
      "Epoch: 123, Loss: 0.6424440145492554\n",
      "Epoch: 124, Loss: 0.647574782371521\n",
      "Epoch: 125, Loss: 0.6317020654678345\n",
      "Epoch: 126, Loss: 0.6563264727592468\n",
      "Epoch: 127, Loss: 0.6800073981285095\n",
      "Epoch: 128, Loss: 0.6468459963798523\n",
      "Epoch: 129, Loss: 0.6758149862289429\n",
      "Epoch: 130, Loss: 0.6264957189559937\n",
      "Epoch: 131, Loss: 0.6979604363441467\n",
      "Epoch: 132, Loss: 0.6741546988487244\n",
      "Epoch: 133, Loss: 0.6446922421455383\n",
      "Epoch: 134, Loss: 0.7106991410255432\n",
      "Epoch: 135, Loss: 0.6506671905517578\n",
      "Epoch: 136, Loss: 0.618388295173645\n",
      "Epoch: 137, Loss: 0.6786078810691833\n",
      "Epoch: 138, Loss: 0.6222479939460754\n",
      "Epoch: 139, Loss: 0.7044989466667175\n",
      "Epoch: 140, Loss: 0.6445789337158203\n",
      "Epoch: 141, Loss: 0.6349517107009888\n",
      "Epoch: 142, Loss: 0.6931013464927673\n",
      "Epoch: 143, Loss: 0.6927863359451294\n",
      "Epoch: 144, Loss: 0.7012896537780762\n",
      "Epoch: 145, Loss: 0.5952865481376648\n",
      "Epoch: 146, Loss: 0.6732762455940247\n",
      "Epoch: 147, Loss: 0.6438601613044739\n",
      "Epoch: 148, Loss: 0.6707849502563477\n",
      "Epoch: 149, Loss: 0.6830214858055115\n",
      "Epoch: 150, Loss: 0.6765772700309753\n",
      "Epoch: 151, Loss: 0.6529086232185364\n",
      "Epoch: 152, Loss: 0.651607096195221\n",
      "Epoch: 153, Loss: 0.6466494798660278\n",
      "Epoch: 154, Loss: 0.7489026188850403\n",
      "Epoch: 155, Loss: 0.6192294359207153\n",
      "Epoch: 156, Loss: 0.6095613241195679\n",
      "Epoch: 157, Loss: 0.6825178861618042\n",
      "Epoch: 158, Loss: 0.6793280839920044\n",
      "Epoch: 159, Loss: 0.6463361382484436\n",
      "Epoch: 160, Loss: 0.6570808291435242\n",
      "Epoch: 161, Loss: 0.673480212688446\n",
      "Epoch: 162, Loss: 0.619871973991394\n",
      "Epoch: 163, Loss: 0.6215518116950989\n",
      "Epoch: 164, Loss: 0.6492781043052673\n",
      "Epoch: 165, Loss: 0.6020134687423706\n",
      "Epoch: 166, Loss: 0.605901300907135\n",
      "Epoch: 167, Loss: 0.6070003509521484\n",
      "Epoch: 168, Loss: 0.6578803658485413\n",
      "Epoch: 169, Loss: 0.672007143497467\n",
      "Epoch: 170, Loss: 0.707301676273346\n",
      "Epoch: 171, Loss: 0.6695400476455688\n",
      "Epoch: 172, Loss: 0.6847229599952698\n",
      "Epoch: 173, Loss: 0.6125735640525818\n",
      "Epoch: 174, Loss: 0.668091356754303\n",
      "Epoch: 175, Loss: 0.6150966882705688\n",
      "Epoch: 176, Loss: 0.7016075253486633\n",
      "Epoch: 177, Loss: 0.6102756857872009\n",
      "Epoch: 178, Loss: 0.7008114457130432\n",
      "Epoch: 179, Loss: 0.644853413105011\n",
      "Epoch: 180, Loss: 0.6366786956787109\n",
      "Epoch: 181, Loss: 0.6471722722053528\n",
      "Epoch: 182, Loss: 0.6456795930862427\n",
      "Epoch: 183, Loss: 0.7148279547691345\n",
      "Epoch: 184, Loss: 0.6865807175636292\n",
      "Epoch: 185, Loss: 0.674347996711731\n",
      "Epoch: 186, Loss: 0.6817956566810608\n",
      "Epoch: 187, Loss: 0.6382960677146912\n",
      "Epoch: 188, Loss: 0.6531670689582825\n",
      "Epoch: 189, Loss: 0.6660996079444885\n",
      "Epoch: 190, Loss: 0.6562479734420776\n",
      "Epoch: 191, Loss: 0.6425886154174805\n",
      "Epoch: 192, Loss: 0.7040838599205017\n",
      "Epoch: 193, Loss: 0.6893488168716431\n",
      "Epoch: 194, Loss: 0.7107424139976501\n",
      "Epoch: 195, Loss: 0.6512900590896606\n",
      "Epoch: 196, Loss: 0.6408087015151978\n",
      "Epoch: 197, Loss: 0.7295671105384827\n",
      "Epoch: 198, Loss: 0.6759905815124512\n",
      "Epoch: 199, Loss: 0.7076178193092346\n",
      "Epoch: 200, Loss: 0.6609282493591309\n",
      "Epoch: 201, Loss: 0.6604939103126526\n",
      "Epoch: 202, Loss: 0.7242875695228577\n",
      "Epoch: 203, Loss: 0.5995675325393677\n",
      "Epoch: 204, Loss: 0.6753989458084106\n",
      "Epoch: 205, Loss: 0.6723609566688538\n",
      "Epoch: 206, Loss: 0.6530641913414001\n",
      "Epoch: 207, Loss: 0.6269121170043945\n",
      "Epoch: 208, Loss: 0.6195975542068481\n",
      "Epoch: 209, Loss: 0.6177605390548706\n",
      "Epoch: 210, Loss: 0.6506360769271851\n",
      "Epoch: 211, Loss: 0.6815086007118225\n",
      "Epoch: 212, Loss: 0.6785770654678345\n",
      "Epoch: 213, Loss: 0.6368685960769653\n",
      "Epoch: 214, Loss: 0.6783313155174255\n",
      "Epoch: 215, Loss: 0.6977841258049011\n",
      "Epoch: 216, Loss: 0.6746800541877747\n",
      "Epoch: 217, Loss: 0.6801100969314575\n",
      "Epoch: 218, Loss: 0.6467390060424805\n",
      "Epoch: 219, Loss: 0.6175867915153503\n",
      "Epoch: 220, Loss: 0.6008389592170715\n",
      "Epoch: 221, Loss: 0.661233127117157\n",
      "Epoch: 222, Loss: 0.6742569208145142\n",
      "Epoch: 223, Loss: 0.6867173314094543\n",
      "Epoch: 224, Loss: 0.6997847557067871\n",
      "Epoch: 225, Loss: 0.6442496180534363\n",
      "Epoch: 226, Loss: 0.5966301560401917\n",
      "Epoch: 227, Loss: 0.7106550335884094\n",
      "Epoch: 228, Loss: 0.6126489639282227\n",
      "Epoch: 229, Loss: 0.6744880676269531\n",
      "Epoch: 230, Loss: 0.6774713397026062\n",
      "Epoch: 231, Loss: 0.6755107641220093\n",
      "Epoch: 232, Loss: 0.659286618232727\n",
      "Epoch: 233, Loss: 0.681159496307373\n",
      "Epoch: 234, Loss: 0.7475014328956604\n",
      "Epoch: 235, Loss: 0.7013855576515198\n",
      "Epoch: 236, Loss: 0.6852356791496277\n",
      "Epoch: 237, Loss: 0.6746023297309875\n",
      "Epoch: 238, Loss: 0.6846498250961304\n",
      "Epoch: 239, Loss: 0.6773463487625122\n",
      "Epoch: 240, Loss: 0.7133182287216187\n",
      "Epoch: 241, Loss: 0.6756181716918945\n",
      "Epoch: 242, Loss: 0.6634668707847595\n",
      "Epoch: 243, Loss: 0.6671371459960938\n",
      "Epoch: 244, Loss: 0.6738815903663635\n",
      "Epoch: 245, Loss: 0.6814256906509399\n",
      "Epoch: 246, Loss: 0.6546972393989563\n",
      "Epoch: 247, Loss: 0.6839514970779419\n",
      "Epoch: 248, Loss: 0.6512371897697449\n",
      "Epoch: 249, Loss: 0.6963197588920593\n",
      "Epoch: 250, Loss: 0.6817044019699097\n",
      "Epoch: 251, Loss: 0.6869203448295593\n",
      "Epoch: 252, Loss: 0.6385096907615662\n",
      "Epoch: 253, Loss: 0.6256669759750366\n",
      "Epoch: 254, Loss: 0.6606345176696777\n",
      "Epoch: 255, Loss: 0.6888860464096069\n",
      "Epoch: 256, Loss: 0.6874855756759644\n",
      "Epoch: 257, Loss: 0.6322126388549805\n",
      "Epoch: 258, Loss: 0.6022060513496399\n",
      "Epoch: 259, Loss: 0.630879282951355\n",
      "Epoch: 260, Loss: 0.6699704527854919\n",
      "Epoch: 261, Loss: 0.6560830473899841\n",
      "Epoch: 262, Loss: 0.6794289350509644\n",
      "Epoch: 263, Loss: 0.6468222737312317\n",
      "Epoch: 264, Loss: 0.6665794253349304\n",
      "Epoch: 265, Loss: 0.6638039946556091\n",
      "Epoch: 266, Loss: 0.7178905606269836\n",
      "Epoch: 267, Loss: 0.6716082692146301\n",
      "Epoch: 268, Loss: 0.7052672505378723\n",
      "Epoch: 269, Loss: 0.7062844038009644\n",
      "Epoch: 270, Loss: 0.6696683168411255\n",
      "Epoch: 271, Loss: 0.6747225522994995\n",
      "Epoch: 272, Loss: 0.6529996991157532\n",
      "Epoch: 273, Loss: 0.6014404296875\n",
      "Epoch: 274, Loss: 0.6870428919792175\n",
      "Epoch: 275, Loss: 0.6750108003616333\n",
      "Epoch: 276, Loss: 0.6556841731071472\n",
      "Epoch: 277, Loss: 0.6618528366088867\n",
      "Epoch: 278, Loss: 0.6918443441390991\n",
      "Epoch: 279, Loss: 0.7061297297477722\n",
      "Epoch: 280, Loss: 0.6350411772727966\n",
      "Epoch: 281, Loss: 0.7147970199584961\n",
      "Epoch: 282, Loss: 0.6830568313598633\n",
      "Epoch: 283, Loss: 0.6343631744384766\n",
      "Epoch: 284, Loss: 0.6653743386268616\n",
      "Epoch: 285, Loss: 0.6273342370986938\n",
      "Epoch: 286, Loss: 0.6994657516479492\n",
      "Epoch: 287, Loss: 0.7146607637405396\n",
      "Epoch: 288, Loss: 0.6953405737876892\n",
      "Epoch: 289, Loss: 0.7009867429733276\n",
      "Epoch: 290, Loss: 0.696726381778717\n",
      "Epoch: 291, Loss: 0.6720460653305054\n",
      "Epoch: 292, Loss: 0.7008320689201355\n",
      "Epoch: 293, Loss: 0.6821483969688416\n",
      "Epoch: 294, Loss: 0.6260345578193665\n",
      "Epoch: 295, Loss: 0.6805461645126343\n",
      "Epoch: 296, Loss: 0.6620777249336243\n",
      "Epoch: 297, Loss: 0.7126646041870117\n",
      "Epoch: 298, Loss: 0.6769356727600098\n",
      "Epoch: 299, Loss: 0.657011866569519\n",
      "Epoch: 300, Loss: 0.6711334586143494\n",
      "Epoch: 301, Loss: 0.6709352731704712\n",
      "Epoch: 302, Loss: 0.7132061719894409\n",
      "Epoch: 303, Loss: 0.5931803584098816\n",
      "Epoch: 304, Loss: 0.6240883469581604\n",
      "Epoch: 305, Loss: 0.6401721239089966\n",
      "Epoch: 306, Loss: 0.6353276371955872\n",
      "Epoch: 307, Loss: 0.6674842834472656\n",
      "Epoch: 308, Loss: 0.6992097496986389\n",
      "Epoch: 309, Loss: 0.6746518015861511\n",
      "Epoch: 310, Loss: 0.6552584767341614\n",
      "Epoch: 311, Loss: 0.6217761039733887\n",
      "Epoch: 312, Loss: 0.6365684270858765\n",
      "Epoch: 313, Loss: 0.6014546155929565\n",
      "Epoch: 314, Loss: 0.6909804344177246\n",
      "Epoch: 315, Loss: 0.6809638738632202\n",
      "Epoch: 316, Loss: 0.6499080061912537\n",
      "Epoch: 317, Loss: 0.6783581376075745\n",
      "Epoch: 318, Loss: 0.6518173217773438\n",
      "Epoch: 319, Loss: 0.6474506258964539\n",
      "Epoch: 320, Loss: 0.697750985622406\n",
      "Epoch: 321, Loss: 0.631219744682312\n",
      "Epoch: 322, Loss: 0.7212826013565063\n",
      "Epoch: 323, Loss: 0.7107939720153809\n",
      "Epoch: 324, Loss: 0.6976318955421448\n",
      "Epoch: 325, Loss: 0.656808078289032\n",
      "Epoch: 326, Loss: 0.6914945244789124\n",
      "Epoch: 327, Loss: 0.6029819846153259\n",
      "Epoch: 328, Loss: 0.6621909737586975\n",
      "Epoch: 329, Loss: 0.6661469340324402\n",
      "Epoch: 330, Loss: 0.6766252517700195\n",
      "Epoch: 331, Loss: 0.648215651512146\n",
      "Epoch: 332, Loss: 0.6584118604660034\n",
      "Epoch: 333, Loss: 0.6575836539268494\n",
      "Epoch: 334, Loss: 0.666622519493103\n",
      "Epoch: 335, Loss: 0.5951123237609863\n",
      "Epoch: 336, Loss: 0.6893868446350098\n",
      "Epoch: 337, Loss: 0.7297073602676392\n",
      "Epoch: 338, Loss: 0.6564627885818481\n",
      "Epoch: 339, Loss: 0.7127693295478821\n",
      "Epoch: 340, Loss: 0.6927725076675415\n",
      "Epoch: 341, Loss: 0.6787419319152832\n",
      "Epoch: 342, Loss: 0.6753689050674438\n",
      "Epoch: 343, Loss: 0.6646983027458191\n",
      "Epoch: 344, Loss: 0.6571717262268066\n",
      "Epoch: 345, Loss: 0.6615962386131287\n",
      "Epoch: 346, Loss: 0.6583972573280334\n",
      "Epoch: 347, Loss: 0.6435015797615051\n",
      "Epoch: 348, Loss: 0.688494861125946\n",
      "Epoch: 349, Loss: 0.6876764297485352\n",
      "Epoch: 350, Loss: 0.6811569333076477\n",
      "Epoch: 351, Loss: 0.6367937326431274\n",
      "Epoch: 352, Loss: 0.667071521282196\n",
      "Epoch: 353, Loss: 0.6547505259513855\n",
      "Epoch: 354, Loss: 0.6492406129837036\n",
      "Epoch: 355, Loss: 0.6847041249275208\n",
      "Epoch: 356, Loss: 0.6929724812507629\n",
      "Epoch: 357, Loss: 0.6531031727790833\n",
      "Epoch: 358, Loss: 0.6601967215538025\n",
      "Epoch: 359, Loss: 0.6680495142936707\n",
      "Epoch: 360, Loss: 0.6280662417411804\n",
      "Epoch: 361, Loss: 0.6170754432678223\n",
      "Epoch: 362, Loss: 0.7183124423027039\n",
      "Epoch: 363, Loss: 0.7113533020019531\n",
      "Epoch: 364, Loss: 0.621993899345398\n",
      "Epoch: 365, Loss: 0.6891080141067505\n",
      "Epoch: 366, Loss: 0.6608783006668091\n",
      "Epoch: 367, Loss: 0.6001976132392883\n",
      "Epoch: 368, Loss: 0.6875981688499451\n",
      "Epoch: 369, Loss: 0.60236656665802\n",
      "Epoch: 370, Loss: 0.6306449174880981\n",
      "Epoch: 371, Loss: 0.6309577226638794\n",
      "Epoch: 372, Loss: 0.7066791653633118\n",
      "Epoch: 373, Loss: 0.6800511479377747\n",
      "Epoch: 374, Loss: 0.6858326196670532\n",
      "Epoch: 375, Loss: 0.687919557094574\n",
      "Epoch: 376, Loss: 0.6448400616645813\n",
      "Epoch: 377, Loss: 0.7036753296852112\n",
      "Epoch: 378, Loss: 0.6784794926643372\n",
      "Epoch: 379, Loss: 0.7023091316223145\n",
      "Epoch: 380, Loss: 0.7773157358169556\n",
      "Epoch: 381, Loss: 0.66932213306427\n",
      "Epoch: 382, Loss: 0.6625069379806519\n",
      "Epoch: 383, Loss: 0.6639131307601929\n",
      "Epoch: 384, Loss: 0.6721765398979187\n",
      "Epoch: 385, Loss: 0.6966572999954224\n",
      "Epoch: 386, Loss: 0.7096195220947266\n",
      "Epoch: 387, Loss: 0.6412516236305237\n",
      "Epoch: 388, Loss: 0.6143293380737305\n",
      "Epoch: 389, Loss: 0.6870894432067871\n",
      "Epoch: 390, Loss: 0.6811032295227051\n",
      "Epoch: 391, Loss: 0.6861022114753723\n",
      "Epoch: 392, Loss: 0.6191024780273438\n",
      "Epoch: 393, Loss: 0.6684663891792297\n",
      "Epoch: 394, Loss: 0.7122936248779297\n",
      "Epoch: 395, Loss: 0.6462546586990356\n",
      "Epoch: 396, Loss: 0.6194122433662415\n",
      "Epoch: 397, Loss: 0.700598418712616\n",
      "Epoch: 398, Loss: 0.6451570391654968\n",
      "Epoch: 399, Loss: 0.6736069917678833\n",
      "Epoch: 400, Loss: 0.7018071413040161\n",
      "Epoch: 401, Loss: 0.6737075448036194\n",
      "Epoch: 402, Loss: 0.6557109951972961\n",
      "Epoch: 403, Loss: 0.6815074682235718\n",
      "Epoch: 404, Loss: 0.6743302941322327\n",
      "Epoch: 405, Loss: 0.6762787699699402\n",
      "Epoch: 406, Loss: 0.6026514172554016\n",
      "Epoch: 407, Loss: 0.6411796808242798\n",
      "Epoch: 408, Loss: 0.6964453458786011\n",
      "Epoch: 409, Loss: 0.6616719365119934\n",
      "Epoch: 410, Loss: 0.6417757868766785\n",
      "Epoch: 411, Loss: 0.7058624029159546\n",
      "Epoch: 412, Loss: 0.7043925523757935\n",
      "Epoch: 413, Loss: 0.7024621963500977\n",
      "Epoch: 414, Loss: 0.678314745426178\n",
      "Epoch: 415, Loss: 0.6650943756103516\n",
      "Epoch: 416, Loss: 0.709096372127533\n",
      "Epoch: 417, Loss: 0.668514609336853\n",
      "Epoch: 418, Loss: 0.7546154260635376\n",
      "Epoch: 419, Loss: 0.6781145334243774\n",
      "Epoch: 420, Loss: 0.6771836280822754\n",
      "Epoch: 421, Loss: 0.6263666152954102\n",
      "Epoch: 422, Loss: 0.7204576134681702\n",
      "Epoch: 423, Loss: 0.7221220135688782\n",
      "Epoch: 424, Loss: 0.6605481505393982\n",
      "Epoch: 425, Loss: 0.6214381456375122\n",
      "Epoch: 426, Loss: 0.6628106832504272\n",
      "Epoch: 427, Loss: 0.623347818851471\n",
      "Epoch: 428, Loss: 0.694230854511261\n",
      "Epoch: 429, Loss: 0.6867384314537048\n",
      "Epoch: 430, Loss: 0.6911224722862244\n",
      "Epoch: 431, Loss: 0.675089955329895\n",
      "Epoch: 432, Loss: 0.6403606534004211\n",
      "Epoch: 433, Loss: 0.6465803384780884\n",
      "Epoch: 434, Loss: 0.6835640072822571\n",
      "Epoch: 435, Loss: 0.6267889142036438\n",
      "Epoch: 436, Loss: 0.6515050530433655\n",
      "Epoch: 437, Loss: 0.6001814603805542\n",
      "Epoch: 438, Loss: 0.6704192757606506\n",
      "Epoch: 439, Loss: 0.7021007537841797\n",
      "Epoch: 440, Loss: 0.738774299621582\n",
      "Epoch: 441, Loss: 0.6567821502685547\n",
      "Epoch: 442, Loss: 0.7201188206672668\n",
      "Epoch: 443, Loss: 0.6518276929855347\n",
      "Epoch: 444, Loss: 0.5929032564163208\n",
      "Epoch: 445, Loss: 0.6904290318489075\n",
      "Epoch: 446, Loss: 0.6429568529129028\n",
      "Epoch: 447, Loss: 0.6090940237045288\n",
      "Epoch: 448, Loss: 0.6313866972923279\n",
      "Epoch: 449, Loss: 0.6364041566848755\n",
      "Epoch: 450, Loss: 0.6586669683456421\n",
      "Epoch: 451, Loss: 0.7009317278862\n",
      "Epoch: 452, Loss: 0.6808391213417053\n",
      "Epoch: 453, Loss: 0.7149609923362732\n",
      "Epoch: 454, Loss: 0.676965594291687\n",
      "Epoch: 455, Loss: 0.7177233695983887\n",
      "Epoch: 456, Loss: 0.7212826609611511\n",
      "Epoch: 457, Loss: 0.6614235043525696\n",
      "Epoch: 458, Loss: 0.6574431657791138\n",
      "Epoch: 459, Loss: 0.5814768075942993\n",
      "Epoch: 460, Loss: 0.7030366063117981\n",
      "Epoch: 461, Loss: 0.6635483503341675\n",
      "Epoch: 462, Loss: 0.7034614682197571\n",
      "Epoch: 463, Loss: 0.6530699133872986\n",
      "Epoch: 464, Loss: 0.6425459980964661\n",
      "Epoch: 465, Loss: 0.6930662393569946\n",
      "Epoch: 466, Loss: 0.6815683245658875\n",
      "Epoch: 467, Loss: 0.6250775456428528\n",
      "Epoch: 468, Loss: 0.6239937543869019\n",
      "Epoch: 469, Loss: 0.6596629023551941\n",
      "Epoch: 470, Loss: 0.6901220679283142\n",
      "Epoch: 471, Loss: 0.6681737303733826\n",
      "Epoch: 472, Loss: 0.6801452040672302\n",
      "Epoch: 473, Loss: 0.6589060425758362\n",
      "Epoch: 474, Loss: 0.6135430932044983\n",
      "Epoch: 475, Loss: 0.647131085395813\n",
      "Epoch: 476, Loss: 0.7015653848648071\n",
      "Epoch: 477, Loss: 0.6844262480735779\n",
      "Epoch: 478, Loss: 0.6414292454719543\n",
      "Epoch: 479, Loss: 0.6911665201187134\n",
      "Epoch: 480, Loss: 0.6722296476364136\n",
      "Epoch: 481, Loss: 0.6652786135673523\n",
      "Epoch: 482, Loss: 0.7032370567321777\n",
      "Epoch: 483, Loss: 0.6344151496887207\n",
      "Epoch: 484, Loss: 0.6042348146438599\n",
      "Epoch: 485, Loss: 0.6840143203735352\n",
      "Epoch: 486, Loss: 0.6860179901123047\n",
      "Epoch: 487, Loss: 0.6708283424377441\n",
      "Epoch: 488, Loss: 0.6846514940261841\n",
      "Epoch: 489, Loss: 0.5712643265724182\n",
      "Epoch: 490, Loss: 0.6888840794563293\n",
      "Epoch: 491, Loss: 0.627741277217865\n",
      "Epoch: 492, Loss: 0.672602653503418\n",
      "Epoch: 493, Loss: 0.6595016121864319\n",
      "Epoch: 494, Loss: 0.6606181263923645\n",
      "Epoch: 495, Loss: 0.6912025809288025\n",
      "Epoch: 496, Loss: 0.6915580630302429\n",
      "Epoch: 497, Loss: 0.7119747400283813\n",
      "Epoch: 498, Loss: 0.6737995743751526\n",
      "Epoch: 499, Loss: 0.6590667963027954\n",
      "Epoch: 500, Loss: 0.6987714171409607\n",
      "Epoch: 501, Loss: 0.672200620174408\n",
      "Epoch: 502, Loss: 0.7056662440299988\n",
      "Epoch: 503, Loss: 0.7198442816734314\n",
      "Epoch: 504, Loss: 0.6521835923194885\n",
      "Epoch: 505, Loss: 0.6705735325813293\n",
      "Epoch: 506, Loss: 0.6547316312789917\n",
      "Epoch: 507, Loss: 0.677241325378418\n",
      "Epoch: 508, Loss: 0.6032856702804565\n",
      "Epoch: 509, Loss: 0.6518763303756714\n",
      "Epoch: 510, Loss: 0.670746922492981\n",
      "Epoch: 511, Loss: 0.6721768975257874\n",
      "Epoch: 512, Loss: 0.6440597176551819\n",
      "Epoch: 513, Loss: 0.6678176522254944\n",
      "Epoch: 514, Loss: 0.6770920157432556\n",
      "Epoch: 515, Loss: 0.6728985905647278\n",
      "Epoch: 516, Loss: 0.5479198694229126\n",
      "Epoch: 517, Loss: 0.6341439485549927\n",
      "Epoch: 518, Loss: 0.6715346574783325\n",
      "Epoch: 519, Loss: 0.6324111819267273\n",
      "Epoch: 520, Loss: 0.6692976355552673\n",
      "Epoch: 521, Loss: 0.5854886770248413\n",
      "Epoch: 522, Loss: 0.7121685743331909\n",
      "Epoch: 523, Loss: 0.6699074506759644\n",
      "Epoch: 524, Loss: 0.6792113184928894\n",
      "Epoch: 525, Loss: 0.6942626237869263\n",
      "Epoch: 526, Loss: 0.6754589080810547\n",
      "Epoch: 527, Loss: 0.6178666949272156\n",
      "Epoch: 528, Loss: 0.6616511940956116\n",
      "Epoch: 529, Loss: 0.6896784901618958\n",
      "Epoch: 530, Loss: 0.6615215539932251\n",
      "Epoch: 531, Loss: 0.6937617659568787\n",
      "Epoch: 532, Loss: 0.6512117385864258\n",
      "Epoch: 533, Loss: 0.6598017811775208\n",
      "Epoch: 534, Loss: 0.6070619225502014\n",
      "Epoch: 535, Loss: 0.7004175186157227\n",
      "Epoch: 536, Loss: 0.6352105140686035\n",
      "Epoch: 537, Loss: 0.660765528678894\n",
      "Epoch: 538, Loss: 0.6719881296157837\n",
      "Epoch: 539, Loss: 0.6415997743606567\n",
      "Epoch: 540, Loss: 0.6826774477958679\n",
      "Epoch: 541, Loss: 0.6228772401809692\n",
      "Epoch: 542, Loss: 0.6530322432518005\n",
      "Epoch: 543, Loss: 0.6914386749267578\n",
      "Epoch: 544, Loss: 0.6653198599815369\n",
      "Epoch: 545, Loss: 0.7016507387161255\n",
      "Epoch: 546, Loss: 0.6222907304763794\n",
      "Epoch: 547, Loss: 0.6310721635818481\n",
      "Epoch: 548, Loss: 0.7011193037033081\n",
      "Epoch: 549, Loss: 0.6433507800102234\n",
      "Epoch: 550, Loss: 0.6797829866409302\n",
      "Epoch: 551, Loss: 0.6359723210334778\n",
      "Epoch: 552, Loss: 0.6583963632583618\n",
      "Epoch: 553, Loss: 0.6475138664245605\n",
      "Epoch: 554, Loss: 0.693686306476593\n",
      "Epoch: 555, Loss: 0.6780565977096558\n",
      "Epoch: 556, Loss: 0.7252522706985474\n",
      "Epoch: 557, Loss: 0.6662276387214661\n",
      "Epoch: 558, Loss: 0.5695333480834961\n",
      "Epoch: 559, Loss: 0.7049330472946167\n",
      "Epoch: 560, Loss: 0.7259975671768188\n",
      "Epoch: 561, Loss: 0.639686644077301\n",
      "Epoch: 562, Loss: 0.6448416709899902\n",
      "Epoch: 563, Loss: 0.6295555830001831\n",
      "Epoch: 564, Loss: 0.6830196976661682\n",
      "Epoch: 565, Loss: 0.6778411269187927\n",
      "Epoch: 566, Loss: 0.6686186790466309\n",
      "Epoch: 567, Loss: 0.6934105753898621\n",
      "Epoch: 568, Loss: 0.7088305354118347\n",
      "Epoch: 569, Loss: 0.6552972197532654\n",
      "Epoch: 570, Loss: 0.6506848335266113\n",
      "Epoch: 571, Loss: 0.6540008187294006\n",
      "Epoch: 572, Loss: 0.6012212038040161\n",
      "Epoch: 573, Loss: 0.6837956309318542\n",
      "Epoch: 574, Loss: 0.6979424357414246\n",
      "Epoch: 575, Loss: 0.6775731444358826\n",
      "Epoch: 576, Loss: 0.7349203824996948\n",
      "Epoch: 577, Loss: 0.6405452489852905\n",
      "Epoch: 578, Loss: 0.6702421307563782\n",
      "Epoch: 579, Loss: 0.6493538618087769\n",
      "Epoch: 580, Loss: 0.675251305103302\n",
      "Epoch: 581, Loss: 0.687220573425293\n",
      "Epoch: 582, Loss: 0.6009784936904907\n",
      "Epoch: 583, Loss: 0.6489338874816895\n",
      "Epoch: 584, Loss: 0.6495171785354614\n",
      "Epoch: 585, Loss: 0.6948577761650085\n",
      "Epoch: 586, Loss: 0.6054894328117371\n",
      "Epoch: 587, Loss: 0.6799298524856567\n",
      "Epoch: 588, Loss: 0.6083762049674988\n",
      "Epoch: 589, Loss: 0.7177662253379822\n",
      "Epoch: 590, Loss: 0.7181525230407715\n",
      "Epoch: 591, Loss: 0.6820520758628845\n",
      "Epoch: 592, Loss: 0.6307360529899597\n",
      "Epoch: 593, Loss: 0.680264413356781\n",
      "Epoch: 594, Loss: 0.6936882138252258\n",
      "Epoch: 595, Loss: 0.667977511882782\n",
      "Epoch: 596, Loss: 0.6536142230033875\n",
      "Epoch: 597, Loss: 0.707187294960022\n",
      "Epoch: 598, Loss: 0.6826335191726685\n",
      "Epoch: 599, Loss: 0.6966447234153748\n",
      "Epoch: 600, Loss: 0.6462546586990356\n",
      "Epoch: 601, Loss: 0.6587604284286499\n",
      "Epoch: 602, Loss: 0.675713837146759\n",
      "Epoch: 603, Loss: 0.6042925119400024\n",
      "Epoch: 604, Loss: 0.726612389087677\n",
      "Epoch: 605, Loss: 0.6823861002922058\n",
      "Epoch: 606, Loss: 0.6845627427101135\n",
      "Epoch: 607, Loss: 0.6432070136070251\n",
      "Epoch: 608, Loss: 0.6403899788856506\n",
      "Epoch: 609, Loss: 0.6795850396156311\n",
      "Epoch: 610, Loss: 0.6516347527503967\n",
      "Epoch: 611, Loss: 0.7127173542976379\n",
      "Epoch: 612, Loss: 0.6786712408065796\n",
      "Epoch: 613, Loss: 0.674535870552063\n",
      "Epoch: 614, Loss: 0.6519009470939636\n",
      "Epoch: 615, Loss: 0.661526083946228\n",
      "Epoch: 616, Loss: 0.701741635799408\n",
      "Epoch: 617, Loss: 0.678741991519928\n",
      "Epoch: 618, Loss: 0.6343632340431213\n",
      "Epoch: 619, Loss: 0.6650283932685852\n",
      "Epoch: 620, Loss: 0.6662124991416931\n",
      "Epoch: 621, Loss: 0.6814419627189636\n",
      "Epoch: 622, Loss: 0.6660557389259338\n",
      "Epoch: 623, Loss: 0.6462129354476929\n",
      "Epoch: 624, Loss: 0.7182846069335938\n",
      "Epoch: 625, Loss: 0.6645808815956116\n",
      "Epoch: 626, Loss: 0.6483389139175415\n",
      "Epoch: 627, Loss: 0.7056969404220581\n",
      "Epoch: 628, Loss: 0.7020736336708069\n",
      "Epoch: 629, Loss: 0.6628599166870117\n",
      "Epoch: 630, Loss: 0.648044228553772\n",
      "Epoch: 631, Loss: 0.6454078555107117\n",
      "Epoch: 632, Loss: 0.6491302847862244\n",
      "Epoch: 633, Loss: 0.6961507201194763\n",
      "Epoch: 634, Loss: 0.6634346842765808\n",
      "Epoch: 635, Loss: 0.6793161630630493\n",
      "Epoch: 636, Loss: 0.6498374938964844\n",
      "Epoch: 637, Loss: 0.6723402142524719\n",
      "Epoch: 638, Loss: 0.7230706214904785\n",
      "Epoch: 639, Loss: 0.64875727891922\n",
      "Epoch: 640, Loss: 0.6253618597984314\n",
      "Epoch: 641, Loss: 0.6714493632316589\n",
      "Epoch: 642, Loss: 0.6750255227088928\n",
      "Epoch: 643, Loss: 0.6715531945228577\n",
      "Epoch: 644, Loss: 0.6473720669746399\n",
      "Epoch: 645, Loss: 0.6968470811843872\n",
      "Epoch: 646, Loss: 0.664112389087677\n",
      "Epoch: 647, Loss: 0.679125189781189\n",
      "Epoch: 648, Loss: 0.6658528447151184\n",
      "Epoch: 649, Loss: 0.657423198223114\n",
      "Epoch: 650, Loss: 0.6573939323425293\n",
      "Epoch: 651, Loss: 0.6802399754524231\n",
      "Epoch: 652, Loss: 0.7019861340522766\n",
      "Epoch: 653, Loss: 0.65516197681427\n",
      "Epoch: 654, Loss: 0.6694714426994324\n",
      "Epoch: 655, Loss: 0.6422153115272522\n",
      "Epoch: 656, Loss: 0.6829727292060852\n",
      "Epoch: 657, Loss: 0.5583027005195618\n",
      "Epoch: 658, Loss: 0.6832914352416992\n",
      "Epoch: 659, Loss: 0.6794413328170776\n",
      "Epoch: 660, Loss: 0.671784520149231\n",
      "Epoch: 661, Loss: 0.6220117807388306\n",
      "Epoch: 662, Loss: 0.6956084966659546\n",
      "Epoch: 663, Loss: 0.7229872345924377\n",
      "Epoch: 664, Loss: 0.7296919226646423\n",
      "Epoch: 665, Loss: 0.6447949409484863\n",
      "Epoch: 666, Loss: 0.6924549341201782\n",
      "Epoch: 667, Loss: 0.6416856646537781\n",
      "Epoch: 668, Loss: 0.6852880716323853\n",
      "Epoch: 669, Loss: 0.7099332809448242\n",
      "Epoch: 670, Loss: 0.6704328656196594\n",
      "Epoch: 671, Loss: 0.6198972463607788\n",
      "Epoch: 672, Loss: 0.6733289957046509\n",
      "Epoch: 673, Loss: 0.6441157460212708\n",
      "Epoch: 674, Loss: 0.7041487693786621\n",
      "Epoch: 675, Loss: 0.6790021061897278\n",
      "Epoch: 676, Loss: 0.6638810038566589\n",
      "Epoch: 677, Loss: 0.6557728052139282\n",
      "Epoch: 678, Loss: 0.6922314763069153\n",
      "Epoch: 679, Loss: 0.665753960609436\n",
      "Epoch: 680, Loss: 0.6112067103385925\n",
      "Epoch: 681, Loss: 0.6788879036903381\n",
      "Epoch: 682, Loss: 0.6223739385604858\n",
      "Epoch: 683, Loss: 0.7002459168434143\n",
      "Epoch: 684, Loss: 0.6949723958969116\n",
      "Epoch: 685, Loss: 0.661311686038971\n",
      "Epoch: 686, Loss: 0.6483477354049683\n",
      "Epoch: 687, Loss: 0.6785349249839783\n",
      "Epoch: 688, Loss: 0.6767377257347107\n",
      "Epoch: 689, Loss: 0.6440340876579285\n",
      "Epoch: 690, Loss: 0.6424600481987\n",
      "Epoch: 691, Loss: 0.680552065372467\n",
      "Epoch: 692, Loss: 0.6839423179626465\n",
      "Epoch: 693, Loss: 0.6939887404441833\n",
      "Epoch: 694, Loss: 0.6659098863601685\n",
      "Epoch: 695, Loss: 0.6241233944892883\n",
      "Epoch: 696, Loss: 0.7020550966262817\n",
      "Epoch: 697, Loss: 0.7059226632118225\n",
      "Epoch: 698, Loss: 0.6820922493934631\n",
      "Epoch: 699, Loss: 0.6857483983039856\n",
      "Epoch: 700, Loss: 0.6859596371650696\n",
      "Epoch: 701, Loss: 0.6832036972045898\n",
      "Epoch: 702, Loss: 0.645490825176239\n",
      "Epoch: 703, Loss: 0.6259190440177917\n",
      "Epoch: 704, Loss: 0.6871663928031921\n",
      "Epoch: 705, Loss: 0.6600794792175293\n",
      "Epoch: 706, Loss: 0.6573992967605591\n",
      "Epoch: 707, Loss: 0.7272316813468933\n",
      "Epoch: 708, Loss: 0.6670679450035095\n",
      "Epoch: 709, Loss: 0.6089128255844116\n",
      "Epoch: 710, Loss: 0.6708163022994995\n",
      "Epoch: 711, Loss: 0.6380156874656677\n",
      "Epoch: 712, Loss: 0.6778809428215027\n",
      "Epoch: 713, Loss: 0.6942036747932434\n",
      "Epoch: 714, Loss: 0.6372078061103821\n",
      "Epoch: 715, Loss: 0.6366638541221619\n",
      "Epoch: 716, Loss: 0.6378918886184692\n",
      "Epoch: 717, Loss: 0.6597663164138794\n",
      "Epoch: 718, Loss: 0.6840583086013794\n",
      "Epoch: 719, Loss: 0.6628488898277283\n",
      "Epoch: 720, Loss: 0.6610903143882751\n",
      "Epoch: 721, Loss: 0.6499037742614746\n",
      "Epoch: 722, Loss: 0.6146556735038757\n",
      "Epoch: 723, Loss: 0.6854826807975769\n",
      "Epoch: 724, Loss: 0.6434571146965027\n",
      "Epoch: 725, Loss: 0.6802352070808411\n",
      "Epoch: 726, Loss: 0.658722460269928\n",
      "Epoch: 727, Loss: 0.6905609965324402\n",
      "Epoch: 728, Loss: 0.6776652932167053\n",
      "Epoch: 729, Loss: 0.6473174691200256\n",
      "Epoch: 730, Loss: 0.7040783166885376\n",
      "Epoch: 731, Loss: 0.6068479418754578\n",
      "Epoch: 732, Loss: 0.6846736073493958\n",
      "Epoch: 733, Loss: 0.6636267304420471\n",
      "Epoch: 734, Loss: 0.665391743183136\n",
      "Epoch: 735, Loss: 0.6397994756698608\n",
      "Epoch: 736, Loss: 0.6568511724472046\n",
      "Epoch: 737, Loss: 0.7055346369743347\n",
      "Epoch: 738, Loss: 0.7036696672439575\n",
      "Epoch: 739, Loss: 0.663447380065918\n",
      "Epoch: 740, Loss: 0.6399854421615601\n",
      "Epoch: 741, Loss: 0.7065338492393494\n",
      "Epoch: 742, Loss: 0.6802539229393005\n",
      "Epoch: 743, Loss: 0.5951240658760071\n",
      "Epoch: 744, Loss: 0.6094388365745544\n",
      "Epoch: 745, Loss: 0.7059196829795837\n",
      "Epoch: 746, Loss: 0.7090086936950684\n",
      "Epoch: 747, Loss: 0.6359764337539673\n",
      "Epoch: 748, Loss: 0.6693423986434937\n",
      "Epoch: 749, Loss: 0.6862326264381409\n",
      "Epoch: 750, Loss: 0.7061253786087036\n",
      "Epoch: 751, Loss: 0.6844469308853149\n",
      "Epoch: 752, Loss: 0.631159245967865\n",
      "Epoch: 753, Loss: 0.6691933870315552\n",
      "Epoch: 754, Loss: 0.6686720848083496\n",
      "Epoch: 755, Loss: 0.6868872046470642\n",
      "Epoch: 756, Loss: 0.6547451615333557\n",
      "Epoch: 757, Loss: 0.7079534530639648\n",
      "Epoch: 758, Loss: 0.7177668213844299\n",
      "Epoch: 759, Loss: 0.6528674960136414\n",
      "Epoch: 760, Loss: 0.6465999484062195\n",
      "Epoch: 761, Loss: 0.6235965490341187\n",
      "Epoch: 762, Loss: 0.6417981386184692\n",
      "Epoch: 763, Loss: 0.6561292409896851\n",
      "Epoch: 764, Loss: 0.6447287797927856\n",
      "Epoch: 765, Loss: 0.6697940826416016\n",
      "Epoch: 766, Loss: 0.7067389488220215\n",
      "Epoch: 767, Loss: 0.6682456135749817\n",
      "Epoch: 768, Loss: 0.6570567488670349\n",
      "Epoch: 769, Loss: 0.6716648936271667\n",
      "Epoch: 770, Loss: 0.6422190070152283\n",
      "Epoch: 771, Loss: 0.6585460305213928\n",
      "Epoch: 772, Loss: 0.6310186386108398\n",
      "Epoch: 773, Loss: 0.6425082087516785\n",
      "Epoch: 774, Loss: 0.7004819512367249\n",
      "Epoch: 775, Loss: 0.6613687872886658\n",
      "Epoch: 776, Loss: 0.7048059105873108\n",
      "Epoch: 777, Loss: 0.664539635181427\n",
      "Epoch: 778, Loss: 0.7143567800521851\n",
      "Epoch: 779, Loss: 0.6942155957221985\n",
      "Epoch: 780, Loss: 0.6304289102554321\n",
      "Epoch: 781, Loss: 0.6843329668045044\n",
      "Epoch: 782, Loss: 0.7236582636833191\n",
      "Epoch: 783, Loss: 0.6625069379806519\n",
      "Epoch: 784, Loss: 0.6479748487472534\n",
      "Epoch: 785, Loss: 0.6510826349258423\n",
      "Epoch: 786, Loss: 0.6882871389389038\n",
      "Epoch: 787, Loss: 0.6588190793991089\n",
      "Epoch: 788, Loss: 0.6503576040267944\n",
      "Epoch: 789, Loss: 0.6534786224365234\n",
      "Epoch: 790, Loss: 0.7050851583480835\n",
      "Epoch: 791, Loss: 0.678109347820282\n",
      "Epoch: 792, Loss: 0.6883352398872375\n",
      "Epoch: 793, Loss: 0.6751495003700256\n",
      "Epoch: 794, Loss: 0.6474124193191528\n",
      "Epoch: 795, Loss: 0.7046231031417847\n",
      "Epoch: 796, Loss: 0.6155267357826233\n",
      "Epoch: 797, Loss: 0.6503000259399414\n",
      "Epoch: 798, Loss: 0.6841021776199341\n",
      "Epoch: 799, Loss: 0.7000583410263062\n",
      "Epoch: 800, Loss: 0.6627958416938782\n",
      "Epoch: 801, Loss: 0.6385055184364319\n",
      "Epoch: 802, Loss: 0.6743426322937012\n",
      "Epoch: 803, Loss: 0.6960964798927307\n",
      "Epoch: 804, Loss: 0.658681333065033\n",
      "Epoch: 805, Loss: 0.6925560832023621\n",
      "Epoch: 806, Loss: 0.6135572195053101\n",
      "Epoch: 807, Loss: 0.6736897826194763\n",
      "Epoch: 808, Loss: 0.5850854516029358\n",
      "Epoch: 809, Loss: 0.610598087310791\n",
      "Epoch: 810, Loss: 0.6388644576072693\n",
      "Epoch: 811, Loss: 0.6721277832984924\n",
      "Epoch: 812, Loss: 0.6422821879386902\n",
      "Epoch: 813, Loss: 0.6873073577880859\n",
      "Epoch: 814, Loss: 0.6419779062271118\n",
      "Epoch: 815, Loss: 0.6643617749214172\n",
      "Epoch: 816, Loss: 0.6493380665779114\n",
      "Epoch: 817, Loss: 0.6467598080635071\n",
      "Epoch: 818, Loss: 0.6617790460586548\n",
      "Epoch: 819, Loss: 0.6243491768836975\n",
      "Epoch: 820, Loss: 0.6933997273445129\n",
      "Epoch: 821, Loss: 0.6839521527290344\n",
      "Epoch: 822, Loss: 0.6666555404663086\n",
      "Epoch: 823, Loss: 0.6173437237739563\n",
      "Epoch: 824, Loss: 0.6893926858901978\n",
      "Epoch: 825, Loss: 0.7315611243247986\n",
      "Epoch: 826, Loss: 0.6727403998374939\n",
      "Epoch: 827, Loss: 0.68155437707901\n",
      "Epoch: 828, Loss: 0.6833127737045288\n",
      "Epoch: 829, Loss: 0.625566840171814\n",
      "Epoch: 830, Loss: 0.707048237323761\n",
      "Epoch: 831, Loss: 0.6563764214515686\n",
      "Epoch: 832, Loss: 0.7051911950111389\n",
      "Epoch: 833, Loss: 0.6508926749229431\n",
      "Epoch: 834, Loss: 0.6719498634338379\n",
      "Epoch: 835, Loss: 0.6434627771377563\n",
      "Epoch: 836, Loss: 0.6439293622970581\n",
      "Epoch: 837, Loss: 0.6479261517524719\n",
      "Epoch: 838, Loss: 0.6367304921150208\n",
      "Epoch: 839, Loss: 0.6724095344543457\n",
      "Epoch: 840, Loss: 0.7094355225563049\n",
      "Epoch: 841, Loss: 0.6619893312454224\n",
      "Epoch: 842, Loss: 0.6952874064445496\n",
      "Epoch: 843, Loss: 0.6544159054756165\n",
      "Epoch: 844, Loss: 0.6822283864021301\n",
      "Epoch: 845, Loss: 0.6644558310508728\n",
      "Epoch: 846, Loss: 0.7120710015296936\n",
      "Epoch: 847, Loss: 0.7119336128234863\n",
      "Epoch: 848, Loss: 0.6580663323402405\n",
      "Epoch: 849, Loss: 0.6519253849983215\n",
      "Epoch: 850, Loss: 0.6587132215499878\n",
      "Epoch: 851, Loss: 0.6817831993103027\n",
      "Epoch: 852, Loss: 0.6634546518325806\n",
      "Epoch: 853, Loss: 0.6300404667854309\n",
      "Epoch: 854, Loss: 0.6855719685554504\n",
      "Epoch: 855, Loss: 0.6585347056388855\n",
      "Epoch: 856, Loss: 0.6705053448677063\n",
      "Epoch: 857, Loss: 0.643317699432373\n",
      "Epoch: 858, Loss: 0.698613703250885\n",
      "Epoch: 859, Loss: 0.68204265832901\n",
      "Epoch: 860, Loss: 0.6954866647720337\n",
      "Epoch: 861, Loss: 0.6825472712516785\n",
      "Epoch: 862, Loss: 0.7135921716690063\n",
      "Epoch: 863, Loss: 0.6233172416687012\n",
      "Epoch: 864, Loss: 0.6794219613075256\n",
      "Epoch: 865, Loss: 0.6738162040710449\n",
      "Epoch: 866, Loss: 0.6553391814231873\n",
      "Epoch: 867, Loss: 0.598814845085144\n",
      "Epoch: 868, Loss: 0.631182849407196\n",
      "Epoch: 869, Loss: 0.7172849774360657\n",
      "Epoch: 870, Loss: 0.6005352139472961\n",
      "Epoch: 871, Loss: 0.626402735710144\n",
      "Epoch: 872, Loss: 0.6832722425460815\n",
      "Epoch: 873, Loss: 0.6469996571540833\n",
      "Epoch: 874, Loss: 0.6431105732917786\n",
      "Epoch: 875, Loss: 0.6860466599464417\n",
      "Epoch: 876, Loss: 0.6820738911628723\n",
      "Epoch: 877, Loss: 0.7382236123085022\n",
      "Epoch: 878, Loss: 0.6841265559196472\n",
      "Epoch: 879, Loss: 0.6236696243286133\n",
      "Epoch: 880, Loss: 0.6289941668510437\n",
      "Epoch: 881, Loss: 0.6427288055419922\n",
      "Epoch: 882, Loss: 0.6586496233940125\n",
      "Epoch: 883, Loss: 0.6478276252746582\n",
      "Epoch: 884, Loss: 0.6433075666427612\n",
      "Epoch: 885, Loss: 0.6971544623374939\n",
      "Epoch: 886, Loss: 0.6694222092628479\n",
      "Epoch: 887, Loss: 0.730709433555603\n",
      "Epoch: 888, Loss: 0.6275544166564941\n",
      "Epoch: 889, Loss: 0.6688902974128723\n",
      "Epoch: 890, Loss: 0.6269400715827942\n",
      "Epoch: 891, Loss: 0.6764939427375793\n",
      "Epoch: 892, Loss: 0.6447901725769043\n",
      "Epoch: 893, Loss: 0.7342371344566345\n",
      "Epoch: 894, Loss: 0.6812410354614258\n",
      "Epoch: 895, Loss: 0.693527102470398\n",
      "Epoch: 896, Loss: 0.6993075609207153\n",
      "Epoch: 897, Loss: 0.7067857980728149\n",
      "Epoch: 898, Loss: 0.6275850534439087\n",
      "Epoch: 899, Loss: 0.7248473167419434\n",
      "Epoch: 900, Loss: 0.6236569285392761\n",
      "Epoch: 901, Loss: 0.6940986514091492\n",
      "Epoch: 902, Loss: 0.6673949360847473\n",
      "Epoch: 903, Loss: 0.6463780403137207\n",
      "Epoch: 904, Loss: 0.6296493411064148\n",
      "Epoch: 905, Loss: 0.6504928469657898\n",
      "Epoch: 906, Loss: 0.6652474403381348\n",
      "Epoch: 907, Loss: 0.7342649102210999\n",
      "Epoch: 908, Loss: 0.6821955442428589\n",
      "Epoch: 909, Loss: 0.6711800694465637\n",
      "Epoch: 910, Loss: 0.6432101130485535\n",
      "Epoch: 911, Loss: 0.6738514304161072\n",
      "Epoch: 912, Loss: 0.6235489249229431\n",
      "Epoch: 913, Loss: 0.7000626921653748\n",
      "Epoch: 914, Loss: 0.720423698425293\n",
      "Epoch: 915, Loss: 0.6804861426353455\n",
      "Epoch: 916, Loss: 0.6173262000083923\n",
      "Epoch: 917, Loss: 0.6601563096046448\n",
      "Epoch: 918, Loss: 0.6941671967506409\n",
      "Epoch: 919, Loss: 0.6990438103675842\n",
      "Epoch: 920, Loss: 0.7268487811088562\n",
      "Epoch: 921, Loss: 0.6402349472045898\n",
      "Epoch: 922, Loss: 0.6540899276733398\n",
      "Epoch: 923, Loss: 0.6703944802284241\n",
      "Epoch: 924, Loss: 0.7244843244552612\n",
      "Epoch: 925, Loss: 0.6751585006713867\n",
      "Epoch: 926, Loss: 0.6400014162063599\n",
      "Epoch: 927, Loss: 0.652075469493866\n",
      "Epoch: 928, Loss: 0.648989200592041\n",
      "Epoch: 929, Loss: 0.6741605401039124\n",
      "Epoch: 930, Loss: 0.5908423662185669\n",
      "Epoch: 931, Loss: 0.6964125633239746\n",
      "Epoch: 932, Loss: 0.6279231309890747\n",
      "Epoch: 933, Loss: 0.6615511178970337\n",
      "Epoch: 934, Loss: 0.6798825263977051\n",
      "Epoch: 935, Loss: 0.6800554990768433\n",
      "Epoch: 936, Loss: 0.6776896715164185\n",
      "Epoch: 937, Loss: 0.6329947710037231\n",
      "Epoch: 938, Loss: 0.6791930794715881\n",
      "Epoch: 939, Loss: 0.6874139904975891\n",
      "Epoch: 940, Loss: 0.6349512934684753\n",
      "Epoch: 941, Loss: 0.6752869486808777\n",
      "Epoch: 942, Loss: 0.6471889615058899\n",
      "Epoch: 943, Loss: 0.6054607033729553\n",
      "Epoch: 944, Loss: 0.6784947514533997\n",
      "Epoch: 945, Loss: 0.6655092239379883\n",
      "Epoch: 946, Loss: 0.6045107841491699\n",
      "Epoch: 947, Loss: 0.6371141672134399\n",
      "Epoch: 948, Loss: 0.6709597706794739\n",
      "Epoch: 949, Loss: 0.7243390679359436\n",
      "Epoch: 950, Loss: 0.665023922920227\n",
      "Epoch: 951, Loss: 0.6816681027412415\n",
      "Epoch: 952, Loss: 0.6224299669265747\n",
      "Epoch: 953, Loss: 0.7039767503738403\n",
      "Epoch: 954, Loss: 0.6708534359931946\n",
      "Epoch: 955, Loss: 0.655238926410675\n",
      "Epoch: 956, Loss: 0.7082687616348267\n",
      "Epoch: 957, Loss: 0.701958954334259\n",
      "Epoch: 958, Loss: 0.6816707253456116\n",
      "Epoch: 959, Loss: 0.6465727686882019\n",
      "Epoch: 960, Loss: 0.6557727456092834\n",
      "Epoch: 961, Loss: 0.6530413627624512\n",
      "Epoch: 962, Loss: 0.6508651971817017\n",
      "Epoch: 963, Loss: 0.6565870642662048\n",
      "Epoch: 964, Loss: 0.6502653360366821\n",
      "Epoch: 965, Loss: 0.6625884175300598\n",
      "Epoch: 966, Loss: 0.6064003705978394\n",
      "Epoch: 967, Loss: 0.6138723492622375\n",
      "Epoch: 968, Loss: 0.7074411511421204\n",
      "Epoch: 969, Loss: 0.6992706656455994\n",
      "Epoch: 970, Loss: 0.6557449698448181\n",
      "Epoch: 971, Loss: 0.638860821723938\n",
      "Epoch: 972, Loss: 0.6574417948722839\n",
      "Epoch: 973, Loss: 0.6807856559753418\n",
      "Epoch: 974, Loss: 0.7058846354484558\n",
      "Epoch: 975, Loss: 0.6403055787086487\n",
      "Epoch: 976, Loss: 0.714520275592804\n",
      "Epoch: 977, Loss: 0.6625005006790161\n",
      "Epoch: 978, Loss: 0.6733586192131042\n",
      "Epoch: 979, Loss: 0.6737171411514282\n",
      "Epoch: 980, Loss: 0.6946232914924622\n",
      "Epoch: 981, Loss: 0.6626030802726746\n",
      "Epoch: 982, Loss: 0.6931241154670715\n",
      "Epoch: 983, Loss: 0.6756345629692078\n",
      "Epoch: 984, Loss: 0.6832047700881958\n",
      "Epoch: 985, Loss: 0.6428478956222534\n",
      "Epoch: 986, Loss: 0.7017534375190735\n",
      "Epoch: 987, Loss: 0.6385393738746643\n",
      "Epoch: 988, Loss: 0.6874211430549622\n",
      "Epoch: 989, Loss: 0.6516185402870178\n",
      "Epoch: 990, Loss: 0.6382735967636108\n",
      "Epoch: 991, Loss: 0.6644560098648071\n",
      "Epoch: 992, Loss: 0.6857734322547913\n",
      "Epoch: 993, Loss: 0.6129177808761597\n",
      "Epoch: 994, Loss: 0.6296161413192749\n",
      "Epoch: 995, Loss: 0.7129708528518677\n",
      "Epoch: 996, Loss: 0.6916848421096802\n",
      "Epoch: 997, Loss: 0.6896181106567383\n",
      "Epoch: 998, Loss: 0.703417956829071\n",
      "Epoch: 999, Loss: 0.6613801717758179\n",
      "Epoch: 1000, Loss: 0.7078922390937805\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        y_pred = model(batch_features)\n",
    "        loss = loss_function(y_pred, batch_labels.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a75de744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5747\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.9).float()\n",
    "\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy: .4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
