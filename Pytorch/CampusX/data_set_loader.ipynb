{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "04ad3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd2716e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available.\n",
      "Using MPS: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available.\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    print(\"MPS available.\")\n",
    "    print(f\"Using MPS: {torch.mps.device_count()}\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_device(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4dd8d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "\n",
    "x, y = make_classification(\n",
    "    n_samples=12,        # Number of samples\n",
    "    n_features=2,        # Number of features\n",
    "    n_informative=2,     # Number of informative features\n",
    "    n_redundant=0,       # Number of redundant features\n",
    "    n_classes=2,         # Number of classes\n",
    "    random_state=42,     # For reproductibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c522b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9d96e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, feartures, labels):\n",
    "        self.features = feartures\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9412a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfd002cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8db9d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5527, -2.5911],\n",
      "        [ 2.2757, -0.1670],\n",
      "        [ 3.0016, -0.1474]])\n",
      "tensor([0., 1., 1.])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.5116, -0.2226],\n",
      "        [-0.0863,  0.9132],\n",
      "        [-1.0306,  0.2967]])\n",
      "tensor([0., 1., 1.])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.9379, -1.3595],\n",
      "        [-1.0936, -0.6333],\n",
      "        [ 0.1023,  0.8010]])\n",
      "tensor([0., 0., 1.])\n",
      "--------------------------------------------------\n",
      "tensor([[ 1.4669,  0.4553],\n",
      "        [-1.6591,  2.8911],\n",
      "        [ 0.2005, -0.9657]])\n",
      "tensor([0., 1., 0.])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch_features, batch_labels in dataloader:\n",
    "\n",
    "    print(batch_features)\n",
    "    print(batch_labels)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "335479a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c8f272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['id', 'Unnamed: 32'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bab7902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73649148",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train).to(dtype=torch.float32, device=device)\n",
    "x_test_tensor = torch.from_numpy(x_test).to(dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.from_numpy(y_train).to(dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.from_numpy(y_test).to(dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "016eb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, feartures, labels):\n",
    "        self.features = feartures\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e03118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CancerDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = CancerDataset(x_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c7328232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78e19dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=3, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=3, out_features=1, device=device),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        out = self.network(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb49949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2569fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(x_train_tensor.shape[1]).to(device=device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab4d1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6197615265846252\n",
      "Epoch: 2, Loss: 0.5268048644065857\n",
      "Epoch: 3, Loss: 0.24264369904994965\n",
      "Epoch: 4, Loss: 0.20525319874286652\n",
      "Epoch: 5, Loss: 0.16420944035053253\n",
      "Epoch: 6, Loss: 0.08108653128147125\n",
      "Epoch: 7, Loss: 0.053193412721157074\n",
      "Epoch: 8, Loss: 0.10267382860183716\n",
      "Epoch: 9, Loss: 0.05230791121721268\n",
      "Epoch: 10, Loss: 0.3086850345134735\n",
      "Epoch: 11, Loss: 0.08979503810405731\n",
      "Epoch: 12, Loss: 0.022370746359229088\n",
      "Epoch: 13, Loss: 0.016022812575101852\n",
      "Epoch: 14, Loss: 0.09543914347887039\n",
      "Epoch: 15, Loss: 0.025396283715963364\n",
      "Epoch: 16, Loss: 0.02010170742869377\n",
      "Epoch: 17, Loss: 0.011669384315609932\n",
      "Epoch: 18, Loss: 0.0018276566406711936\n",
      "Epoch: 19, Loss: 0.003944388125091791\n",
      "Epoch: 20, Loss: 0.0009329589665867388\n",
      "Epoch: 21, Loss: 0.010786147788167\n",
      "Epoch: 22, Loss: 0.0018729480216279626\n",
      "Epoch: 23, Loss: 0.19289268553256989\n",
      "Epoch: 24, Loss: 0.025507645681500435\n",
      "Epoch: 25, Loss: 0.026140540838241577\n",
      "Epoch: 26, Loss: 0.00594195444136858\n",
      "Epoch: 27, Loss: 0.007892879657447338\n",
      "Epoch: 28, Loss: 0.0066553452052176\n",
      "Epoch: 29, Loss: 0.016188595443964005\n",
      "Epoch: 30, Loss: 0.0044165970757603645\n",
      "Epoch: 31, Loss: 0.0022668843157589436\n",
      "Epoch: 32, Loss: 0.043093036860227585\n",
      "Epoch: 33, Loss: 0.013248826377093792\n",
      "Epoch: 34, Loss: 0.0014063142007216811\n",
      "Epoch: 35, Loss: 0.002619211794808507\n",
      "Epoch: 36, Loss: 0.006220542825758457\n",
      "Epoch: 37, Loss: 0.010342258028686047\n",
      "Epoch: 38, Loss: 0.0018273863242939115\n",
      "Epoch: 39, Loss: 0.04934551194310188\n",
      "Epoch: 40, Loss: 0.0010676824022084475\n",
      "Epoch: 41, Loss: 0.008664368651807308\n",
      "Epoch: 42, Loss: 0.043727364391088486\n",
      "Epoch: 43, Loss: 0.0024555788841098547\n",
      "Epoch: 44, Loss: 0.04886515066027641\n",
      "Epoch: 45, Loss: 0.04053119197487831\n",
      "Epoch: 46, Loss: 0.0009224206442013383\n",
      "Epoch: 47, Loss: 0.00502812210470438\n",
      "Epoch: 48, Loss: 0.010166428051888943\n",
      "Epoch: 49, Loss: 0.003202021587640047\n",
      "Epoch: 50, Loss: 0.0031618790235370398\n",
      "Epoch: 51, Loss: 0.008139437064528465\n",
      "Epoch: 52, Loss: 0.01073519792407751\n",
      "Epoch: 53, Loss: 0.01186402328312397\n",
      "Epoch: 54, Loss: 0.024690359830856323\n",
      "Epoch: 55, Loss: 0.021608099341392517\n",
      "Epoch: 56, Loss: 0.613133430480957\n",
      "Epoch: 57, Loss: 0.031940605491399765\n",
      "Epoch: 58, Loss: 0.08587843924760818\n",
      "Epoch: 59, Loss: 0.004002056550234556\n",
      "Epoch: 60, Loss: 0.006725693587213755\n",
      "Epoch: 61, Loss: 0.002812825608998537\n",
      "Epoch: 62, Loss: 0.028168916702270508\n",
      "Epoch: 63, Loss: 0.047025471925735474\n",
      "Epoch: 64, Loss: 0.0016869179671630263\n",
      "Epoch: 65, Loss: 0.0003126518859062344\n",
      "Epoch: 66, Loss: 0.002701799152418971\n",
      "Epoch: 67, Loss: 0.0648823082447052\n",
      "Epoch: 68, Loss: 0.0012615000596269965\n",
      "Epoch: 69, Loss: 0.07391636818647385\n",
      "Epoch: 70, Loss: 0.06569119542837143\n",
      "Epoch: 71, Loss: 0.006317594088613987\n",
      "Epoch: 72, Loss: 0.0004806336364708841\n",
      "Epoch: 73, Loss: 0.0003509425150696188\n",
      "Epoch: 74, Loss: 0.34736084938049316\n",
      "Epoch: 75, Loss: 0.43535611033439636\n",
      "Epoch: 76, Loss: 0.03250284865498543\n",
      "Epoch: 77, Loss: 0.00150029337964952\n",
      "Epoch: 78, Loss: 0.00824307557195425\n",
      "Epoch: 79, Loss: 0.0050425142981112\n",
      "Epoch: 80, Loss: 0.07262984663248062\n",
      "Epoch: 81, Loss: 0.07674594223499298\n",
      "Epoch: 82, Loss: 0.008845859207212925\n",
      "Epoch: 83, Loss: 0.5039642453193665\n",
      "Epoch: 84, Loss: 0.010536475107073784\n",
      "Epoch: 85, Loss: 0.0025083881337195635\n",
      "Epoch: 86, Loss: 0.07472773641347885\n",
      "Epoch: 87, Loss: 0.03965398296713829\n",
      "Epoch: 88, Loss: 0.3620521128177643\n",
      "Epoch: 89, Loss: 0.14739207923412323\n",
      "Epoch: 90, Loss: 0.03888649865984917\n",
      "Epoch: 91, Loss: 0.013084040954709053\n",
      "Epoch: 92, Loss: 0.0017710410756990314\n",
      "Epoch: 93, Loss: 0.0025360051076859236\n",
      "Epoch: 94, Loss: 0.058801401406526566\n",
      "Epoch: 95, Loss: 0.33447080850601196\n",
      "Epoch: 96, Loss: 0.0025902539491653442\n",
      "Epoch: 97, Loss: 0.006394862197339535\n",
      "Epoch: 98, Loss: 0.01945596933364868\n",
      "Epoch: 99, Loss: 0.027105851098895073\n",
      "Epoch: 100, Loss: 0.01968998648226261\n",
      "Epoch: 101, Loss: 0.08240775763988495\n",
      "Epoch: 102, Loss: 0.04424068331718445\n",
      "Epoch: 103, Loss: 0.004558595363050699\n",
      "Epoch: 104, Loss: 0.015512124635279179\n",
      "Epoch: 105, Loss: 0.0370401069521904\n",
      "Epoch: 106, Loss: 0.0005442264373414218\n",
      "Epoch: 107, Loss: 0.03788517042994499\n",
      "Epoch: 108, Loss: 0.05094263330101967\n",
      "Epoch: 109, Loss: 0.0010178083321079612\n",
      "Epoch: 110, Loss: 0.03416866809129715\n",
      "Epoch: 111, Loss: 0.012901966460049152\n",
      "Epoch: 112, Loss: 0.004899672698229551\n",
      "Epoch: 113, Loss: 0.007412322796881199\n",
      "Epoch: 114, Loss: 0.0010283825686201453\n",
      "Epoch: 115, Loss: 0.39156171679496765\n",
      "Epoch: 116, Loss: 0.010732779279351234\n",
      "Epoch: 117, Loss: 0.027129072695970535\n",
      "Epoch: 118, Loss: 0.009849709458649158\n",
      "Epoch: 119, Loss: 0.004988198168575764\n",
      "Epoch: 120, Loss: 0.02189015969634056\n",
      "Epoch: 121, Loss: 0.00274277594871819\n",
      "Epoch: 122, Loss: 0.009309759363532066\n",
      "Epoch: 123, Loss: 0.08839458972215652\n",
      "Epoch: 124, Loss: 0.002831229940056801\n",
      "Epoch: 125, Loss: 0.0017202608287334442\n",
      "Epoch: 126, Loss: 0.048051618039608\n",
      "Epoch: 127, Loss: 0.0014157984405755997\n",
      "Epoch: 128, Loss: 0.0011635812697932124\n",
      "Epoch: 129, Loss: 0.010373258031904697\n",
      "Epoch: 130, Loss: 0.021202722564339638\n",
      "Epoch: 131, Loss: 0.33492350578308105\n",
      "Epoch: 132, Loss: 0.012214263901114464\n",
      "Epoch: 133, Loss: 0.00037999640335328877\n",
      "Epoch: 134, Loss: 0.33140674233436584\n",
      "Epoch: 135, Loss: 0.012044154107570648\n",
      "Epoch: 136, Loss: 0.045444078743457794\n",
      "Epoch: 137, Loss: 0.003089696867391467\n",
      "Epoch: 138, Loss: 0.005972686223685741\n",
      "Epoch: 139, Loss: 0.000496427237521857\n",
      "Epoch: 140, Loss: 0.0039944835007190704\n",
      "Epoch: 141, Loss: 0.01558473240584135\n",
      "Epoch: 142, Loss: 0.002459441078826785\n",
      "Epoch: 143, Loss: 0.004879300948232412\n",
      "Epoch: 144, Loss: 0.1178838461637497\n",
      "Epoch: 145, Loss: 0.0060891397297382355\n",
      "Epoch: 146, Loss: 0.003423841204494238\n",
      "Epoch: 147, Loss: 0.003707726951688528\n",
      "Epoch: 148, Loss: 0.009624631144106388\n",
      "Epoch: 149, Loss: 0.007887269370257854\n",
      "Epoch: 150, Loss: 0.0003168045950587839\n",
      "Epoch: 151, Loss: 0.002591205295175314\n",
      "Epoch: 152, Loss: 0.00040056632133200765\n",
      "Epoch: 153, Loss: 0.00013051058340352029\n",
      "Epoch: 154, Loss: 0.007816052995622158\n",
      "Epoch: 155, Loss: 0.01961353048682213\n",
      "Epoch: 156, Loss: 0.00038311691605485976\n",
      "Epoch: 157, Loss: 0.006361064966768026\n",
      "Epoch: 158, Loss: 0.11931246519088745\n",
      "Epoch: 159, Loss: 0.0016573121538385749\n",
      "Epoch: 160, Loss: 0.001093402854166925\n",
      "Epoch: 161, Loss: 0.0013593713520094752\n",
      "Epoch: 162, Loss: 0.015668420121073723\n",
      "Epoch: 163, Loss: 0.001630329410545528\n",
      "Epoch: 164, Loss: 0.007260719779878855\n",
      "Epoch: 165, Loss: 0.0069451965391635895\n",
      "Epoch: 166, Loss: 0.006341592874377966\n",
      "Epoch: 167, Loss: 0.004413339775055647\n",
      "Epoch: 168, Loss: 0.03097660467028618\n",
      "Epoch: 169, Loss: 0.06008601561188698\n",
      "Epoch: 170, Loss: 0.10250778496265411\n",
      "Epoch: 171, Loss: 0.07808201760053635\n",
      "Epoch: 172, Loss: 0.020094871520996094\n",
      "Epoch: 173, Loss: 0.004233078565448523\n",
      "Epoch: 174, Loss: 0.0015228332486003637\n",
      "Epoch: 175, Loss: 0.003280582372099161\n",
      "Epoch: 176, Loss: 0.01911715604364872\n",
      "Epoch: 177, Loss: 0.0239604152739048\n",
      "Epoch: 178, Loss: 0.0006172267603687942\n",
      "Epoch: 179, Loss: 0.011677754111588001\n",
      "Epoch: 180, Loss: 0.02611158788204193\n",
      "Epoch: 181, Loss: 0.04811280220746994\n",
      "Epoch: 182, Loss: 0.008325621485710144\n",
      "Epoch: 183, Loss: 0.00018291831656824797\n",
      "Epoch: 184, Loss: 0.07602202892303467\n",
      "Epoch: 185, Loss: 0.002614598721265793\n",
      "Epoch: 186, Loss: 0.03512877598404884\n",
      "Epoch: 187, Loss: 0.005472579039633274\n",
      "Epoch: 188, Loss: 0.0007623283308930695\n",
      "Epoch: 189, Loss: 0.09199968725442886\n",
      "Epoch: 190, Loss: 0.050062306225299835\n",
      "Epoch: 191, Loss: 3.542542253853753e-05\n",
      "Epoch: 192, Loss: 0.0008397108758799732\n",
      "Epoch: 193, Loss: 0.020668823271989822\n",
      "Epoch: 194, Loss: 0.0020115526858717203\n",
      "Epoch: 195, Loss: 0.00020460486121010035\n",
      "Epoch: 196, Loss: 0.0005478885141201317\n",
      "Epoch: 197, Loss: 0.01958875171840191\n",
      "Epoch: 198, Loss: 0.0002353563904762268\n",
      "Epoch: 199, Loss: 0.004426509607583284\n",
      "Epoch: 200, Loss: 0.0020563851576298475\n",
      "Epoch: 201, Loss: 0.00028857501456514\n",
      "Epoch: 202, Loss: 0.003640111070126295\n",
      "Epoch: 203, Loss: 6.645659595960751e-05\n",
      "Epoch: 204, Loss: 0.0034843143075704575\n",
      "Epoch: 205, Loss: 0.00013837825099471956\n",
      "Epoch: 206, Loss: 0.04111248627305031\n",
      "Epoch: 207, Loss: 0.00037349408376030624\n",
      "Epoch: 208, Loss: 0.002027680864557624\n",
      "Epoch: 209, Loss: 0.0061778477393090725\n",
      "Epoch: 210, Loss: 0.021711260080337524\n",
      "Epoch: 211, Loss: 0.0025315205566585064\n",
      "Epoch: 212, Loss: 0.007402748800814152\n",
      "Epoch: 213, Loss: 0.000958875403739512\n",
      "Epoch: 214, Loss: 0.026157667860388756\n",
      "Epoch: 215, Loss: 0.000789112295024097\n",
      "Epoch: 216, Loss: 0.05849778279662132\n",
      "Epoch: 217, Loss: 0.20722131431102753\n",
      "Epoch: 218, Loss: 0.005462971515953541\n",
      "Epoch: 219, Loss: 0.047362979501485825\n",
      "Epoch: 220, Loss: 0.004619228653609753\n",
      "Epoch: 221, Loss: 0.0008110505295917392\n",
      "Epoch: 222, Loss: 0.0030896773096174\n",
      "Epoch: 223, Loss: 0.02910134196281433\n",
      "Epoch: 224, Loss: 0.0003632392908912152\n",
      "Epoch: 225, Loss: 0.0468142144382\n",
      "Epoch: 226, Loss: 0.000935343443416059\n",
      "Epoch: 227, Loss: 0.170196071267128\n",
      "Epoch: 228, Loss: 0.010296277701854706\n",
      "Epoch: 229, Loss: 0.0038365167565643787\n",
      "Epoch: 230, Loss: 2.572825542301871e-05\n",
      "Epoch: 231, Loss: 0.019613023847341537\n",
      "Epoch: 232, Loss: 0.00287710502743721\n",
      "Epoch: 233, Loss: 0.0021268236450850964\n",
      "Epoch: 234, Loss: 0.007510188035666943\n",
      "Epoch: 235, Loss: 1.349649846815737e-05\n",
      "Epoch: 236, Loss: 0.0005367370322346687\n",
      "Epoch: 237, Loss: 0.07513805478811264\n",
      "Epoch: 238, Loss: 0.0003827769833151251\n",
      "Epoch: 239, Loss: 0.006474037654697895\n",
      "Epoch: 240, Loss: 0.0004216399975121021\n",
      "Epoch: 241, Loss: 3.9325579564319924e-05\n",
      "Epoch: 242, Loss: 0.0014198863646015525\n",
      "Epoch: 243, Loss: 0.00036668707616627216\n",
      "Epoch: 244, Loss: 0.1679590940475464\n",
      "Epoch: 245, Loss: 0.031014859676361084\n",
      "Epoch: 246, Loss: 0.008933438919484615\n",
      "Epoch: 247, Loss: 0.0747021809220314\n",
      "Epoch: 248, Loss: 0.005089933983981609\n",
      "Epoch: 249, Loss: 0.021617425605654716\n",
      "Epoch: 250, Loss: 0.001996701117604971\n",
      "Epoch: 251, Loss: 9.915977716445923e-05\n",
      "Epoch: 252, Loss: 0.04126418009400368\n",
      "Epoch: 253, Loss: 0.019527556374669075\n",
      "Epoch: 254, Loss: 0.0004774808476213366\n",
      "Epoch: 255, Loss: 0.005225969012826681\n",
      "Epoch: 256, Loss: 0.0025262106209993362\n",
      "Epoch: 257, Loss: 0.04354334622621536\n",
      "Epoch: 258, Loss: 0.00032933641341514885\n",
      "Epoch: 259, Loss: 0.004571590106934309\n",
      "Epoch: 260, Loss: 0.022548943758010864\n",
      "Epoch: 261, Loss: 0.012164698913693428\n",
      "Epoch: 262, Loss: 0.0036720784846693277\n",
      "Epoch: 263, Loss: 0.004457120317965746\n",
      "Epoch: 264, Loss: 0.16415981948375702\n",
      "Epoch: 265, Loss: 0.0012514442205429077\n",
      "Epoch: 266, Loss: 0.004089438822120428\n",
      "Epoch: 267, Loss: 0.15855982899665833\n",
      "Epoch: 268, Loss: 0.001179552054964006\n",
      "Epoch: 269, Loss: 0.3103722035884857\n",
      "Epoch: 270, Loss: 0.10548485070466995\n",
      "Epoch: 271, Loss: 0.0791122317314148\n",
      "Epoch: 272, Loss: 0.0012786351144313812\n",
      "Epoch: 273, Loss: 4.324605015426641e-06\n",
      "Epoch: 274, Loss: 7.305642793653533e-05\n",
      "Epoch: 275, Loss: 4.6656332415295765e-05\n",
      "Epoch: 276, Loss: 0.0012882295995950699\n",
      "Epoch: 277, Loss: 0.002112427493557334\n",
      "Epoch: 278, Loss: 0.04584765061736107\n",
      "Epoch: 279, Loss: 0.0011036759242415428\n",
      "Epoch: 280, Loss: 5.337811671779491e-05\n",
      "Epoch: 281, Loss: 0.0006651654257439077\n",
      "Epoch: 282, Loss: 0.0017839007778093219\n",
      "Epoch: 283, Loss: 0.0007430739351548254\n",
      "Epoch: 284, Loss: 0.0013266417663544416\n",
      "Epoch: 285, Loss: 0.00010107214620802552\n",
      "Epoch: 286, Loss: 0.03173746541142464\n",
      "Epoch: 287, Loss: 0.00015656519099138677\n",
      "Epoch: 288, Loss: 0.0016030521364882588\n",
      "Epoch: 289, Loss: 0.0015771599719300866\n",
      "Epoch: 290, Loss: 0.3015996515750885\n",
      "Epoch: 291, Loss: 0.004813513718545437\n",
      "Epoch: 292, Loss: 0.00048372233868576586\n",
      "Epoch: 293, Loss: 0.005643165670335293\n",
      "Epoch: 294, Loss: 0.00031596148619428277\n",
      "Epoch: 295, Loss: 0.0011516496306285262\n",
      "Epoch: 296, Loss: 0.0001590949686942622\n",
      "Epoch: 297, Loss: 0.008789815939962864\n",
      "Epoch: 298, Loss: 5.618183422484435e-05\n",
      "Epoch: 299, Loss: 0.275432825088501\n",
      "Epoch: 300, Loss: 0.014071152545511723\n",
      "Epoch: 301, Loss: 0.0066839298233389854\n",
      "Epoch: 302, Loss: 0.0002224476629635319\n",
      "Epoch: 303, Loss: 0.015179833397269249\n",
      "Epoch: 304, Loss: 0.0003426141629461199\n",
      "Epoch: 305, Loss: 0.0014001947129145265\n",
      "Epoch: 306, Loss: 0.00023768263054080307\n",
      "Epoch: 307, Loss: 0.0010116338962689042\n",
      "Epoch: 308, Loss: 2.7145782951265574e-05\n",
      "Epoch: 309, Loss: 0.00946639385074377\n",
      "Epoch: 310, Loss: 0.0001827847008826211\n",
      "Epoch: 311, Loss: 0.00013232228229753673\n",
      "Epoch: 312, Loss: 0.003191151190549135\n",
      "Epoch: 313, Loss: 0.024583449587225914\n",
      "Epoch: 314, Loss: 0.017735112458467484\n",
      "Epoch: 315, Loss: 0.020864304155111313\n",
      "Epoch: 316, Loss: 0.010535108856856823\n",
      "Epoch: 317, Loss: 0.034295737743377686\n",
      "Epoch: 318, Loss: 5.886901999474503e-05\n",
      "Epoch: 319, Loss: 0.001326562138274312\n",
      "Epoch: 320, Loss: 0.038431454449892044\n",
      "Epoch: 321, Loss: 0.000280357722658664\n",
      "Epoch: 322, Loss: 0.0001574397028889507\n",
      "Epoch: 323, Loss: 6.530178507091478e-05\n",
      "Epoch: 324, Loss: 0.15310657024383545\n",
      "Epoch: 325, Loss: 0.0014439254300668836\n",
      "Epoch: 326, Loss: 0.00015722715761512518\n",
      "Epoch: 327, Loss: 0.024895789101719856\n",
      "Epoch: 328, Loss: 0.0013840633910149336\n",
      "Epoch: 329, Loss: 0.029856417328119278\n",
      "Epoch: 330, Loss: 0.002727670129388571\n",
      "Epoch: 331, Loss: 9.921270975610241e-05\n",
      "Epoch: 332, Loss: 0.0029174063820391893\n",
      "Epoch: 333, Loss: 0.030718456953763962\n",
      "Epoch: 334, Loss: 0.0001223133149323985\n",
      "Epoch: 335, Loss: 0.002473169704899192\n",
      "Epoch: 336, Loss: 0.0004958496429026127\n",
      "Epoch: 337, Loss: 0.016811024397611618\n",
      "Epoch: 338, Loss: 4.588357842294499e-05\n",
      "Epoch: 339, Loss: 0.0017487357836216688\n",
      "Epoch: 340, Loss: 0.0011039929231628776\n",
      "Epoch: 341, Loss: 0.26696833968162537\n",
      "Epoch: 342, Loss: 0.0030452844221144915\n",
      "Epoch: 343, Loss: 0.11615922302007675\n",
      "Epoch: 344, Loss: 0.004369841422885656\n",
      "Epoch: 345, Loss: 5.909239189350046e-05\n",
      "Epoch: 346, Loss: 2.5663201085990295e-05\n",
      "Epoch: 347, Loss: 0.004564281087368727\n",
      "Epoch: 348, Loss: 0.002425092039629817\n",
      "Epoch: 349, Loss: 0.0017348488327115774\n",
      "Epoch: 350, Loss: 0.03595646470785141\n",
      "Epoch: 351, Loss: 0.00318734347820282\n",
      "Epoch: 352, Loss: 0.0011570925125852227\n",
      "Epoch: 353, Loss: 0.0005262375925667584\n",
      "Epoch: 354, Loss: 0.0028344576712697744\n",
      "Epoch: 355, Loss: 0.00010834732529474422\n",
      "Epoch: 356, Loss: 0.034691911190748215\n",
      "Epoch: 357, Loss: 0.011910922825336456\n",
      "Epoch: 358, Loss: 2.004590533033479e-05\n",
      "Epoch: 359, Loss: 0.00018157837621401995\n",
      "Epoch: 360, Loss: 1.9238537788623944e-05\n",
      "Epoch: 361, Loss: 0.003025779966264963\n",
      "Epoch: 362, Loss: 0.0014850851148366928\n",
      "Epoch: 363, Loss: 0.0026111360639333725\n",
      "Epoch: 364, Loss: 0.010208440013229847\n",
      "Epoch: 365, Loss: 0.028882207348942757\n",
      "Epoch: 366, Loss: 0.01250745914876461\n",
      "Epoch: 367, Loss: 6.513495463877916e-05\n",
      "Epoch: 368, Loss: 7.686774915782735e-05\n",
      "Epoch: 369, Loss: 0.00031081013730727136\n",
      "Epoch: 370, Loss: 7.178472878877074e-05\n",
      "Epoch: 371, Loss: 0.00220343261025846\n",
      "Epoch: 372, Loss: 0.00023234270338434726\n",
      "Epoch: 373, Loss: 0.0029525081627070904\n",
      "Epoch: 374, Loss: 1.276533930649748e-05\n",
      "Epoch: 375, Loss: 0.00033355975756421685\n",
      "Epoch: 376, Loss: 0.013342062942683697\n",
      "Epoch: 377, Loss: 0.029981154948472977\n",
      "Epoch: 378, Loss: 0.0025226324796676636\n",
      "Epoch: 379, Loss: 0.0006909455405548215\n",
      "Epoch: 380, Loss: 0.023502035066485405\n",
      "Epoch: 381, Loss: 0.00218199728988111\n",
      "Epoch: 382, Loss: 0.0027616224251687527\n",
      "Epoch: 383, Loss: 0.0014010242884978652\n",
      "Epoch: 384, Loss: 2.98676204693038e-05\n",
      "Epoch: 385, Loss: 0.00042539864080026746\n",
      "Epoch: 386, Loss: 4.6768025640631095e-05\n",
      "Epoch: 387, Loss: 0.033197544515132904\n",
      "Epoch: 388, Loss: 0.032786931842565536\n",
      "Epoch: 389, Loss: 0.0005551466019824147\n",
      "Epoch: 390, Loss: 0.0003126831434201449\n",
      "Epoch: 391, Loss: 0.0032624860759824514\n",
      "Epoch: 392, Loss: 0.0021242883522063494\n",
      "Epoch: 393, Loss: 0.0003303044941276312\n",
      "Epoch: 394, Loss: 0.0006462751771323383\n",
      "Epoch: 395, Loss: 0.0025980062782764435\n",
      "Epoch: 396, Loss: 5.457314273371594e-06\n",
      "Epoch: 397, Loss: 2.822904207278043e-05\n",
      "Epoch: 398, Loss: 0.0007020495249889791\n",
      "Epoch: 399, Loss: 0.014190122485160828\n",
      "Epoch: 400, Loss: 0.0026695500127971172\n",
      "Epoch: 401, Loss: 5.142726513440721e-05\n",
      "Epoch: 402, Loss: 2.3006185074336827e-05\n",
      "Epoch: 403, Loss: 0.0004628117603715509\n",
      "Epoch: 404, Loss: 0.002592720091342926\n",
      "Epoch: 405, Loss: 0.00022550637368112803\n",
      "Epoch: 406, Loss: 0.010950363241136074\n",
      "Epoch: 407, Loss: 0.0006276569329202175\n",
      "Epoch: 408, Loss: 0.0030081088189035654\n",
      "Epoch: 409, Loss: 0.011199644766747952\n",
      "Epoch: 410, Loss: 0.06329195946455002\n",
      "Epoch: 411, Loss: 6.438888522097841e-05\n",
      "Epoch: 412, Loss: 0.014271912164986134\n",
      "Epoch: 413, Loss: 0.005615429021418095\n",
      "Epoch: 414, Loss: 0.001948848250322044\n",
      "Epoch: 415, Loss: 0.004249610006809235\n",
      "Epoch: 416, Loss: 0.0001794572890503332\n",
      "Epoch: 417, Loss: 0.0215075071901083\n",
      "Epoch: 418, Loss: 0.00010962453234242275\n",
      "Epoch: 419, Loss: 0.019740719348192215\n",
      "Epoch: 420, Loss: 0.00010009716788772494\n",
      "Epoch: 421, Loss: 0.00010041119821835309\n",
      "Epoch: 422, Loss: 0.0030345232225954533\n",
      "Epoch: 423, Loss: 0.029410630464553833\n",
      "Epoch: 424, Loss: 0.001123894122429192\n",
      "Epoch: 425, Loss: 0.07274777442216873\n",
      "Epoch: 426, Loss: 0.021495258435606956\n",
      "Epoch: 427, Loss: 1.5209615412459243e-05\n",
      "Epoch: 428, Loss: 0.00017928129818756133\n",
      "Epoch: 429, Loss: 0.00036887009628117085\n",
      "Epoch: 430, Loss: 0.015054932795464993\n",
      "Epoch: 431, Loss: 0.00021660553466062993\n",
      "Epoch: 432, Loss: 3.113094498985447e-05\n",
      "Epoch: 433, Loss: 0.0029278360307216644\n",
      "Epoch: 434, Loss: 0.0019407037179917097\n",
      "Epoch: 435, Loss: 0.00013669938198290765\n",
      "Epoch: 436, Loss: 0.008559087291359901\n",
      "Epoch: 437, Loss: 0.033797670155763626\n",
      "Epoch: 438, Loss: 0.013299920596182346\n",
      "Epoch: 439, Loss: 9.906697960104793e-05\n",
      "Epoch: 440, Loss: 0.027392596006393433\n",
      "Epoch: 441, Loss: 0.016942059621214867\n",
      "Epoch: 442, Loss: 9.495094127487391e-05\n",
      "Epoch: 443, Loss: 0.00017231081437785178\n",
      "Epoch: 444, Loss: 0.0001728463830659166\n",
      "Epoch: 445, Loss: 1.6834650523378514e-05\n",
      "Epoch: 446, Loss: 0.06348322331905365\n",
      "Epoch: 447, Loss: 5.334884190233424e-05\n",
      "Epoch: 448, Loss: 0.00015210722631309181\n",
      "Epoch: 449, Loss: 0.00010035762534243986\n",
      "Epoch: 450, Loss: 0.0009788454044610262\n",
      "Epoch: 451, Loss: 0.0032721536699682474\n",
      "Epoch: 452, Loss: 0.011531281284987926\n",
      "Epoch: 453, Loss: 0.0032610739581286907\n",
      "Epoch: 454, Loss: 0.004926188848912716\n",
      "Epoch: 455, Loss: 0.00010264197044307366\n",
      "Epoch: 456, Loss: 0.0026968561578541994\n",
      "Epoch: 457, Loss: 0.00095343281282112\n",
      "Epoch: 458, Loss: 9.985495853470638e-05\n",
      "Epoch: 459, Loss: 4.795063432538882e-05\n",
      "Epoch: 460, Loss: 0.03277546539902687\n",
      "Epoch: 461, Loss: 8.435548807028681e-05\n",
      "Epoch: 462, Loss: 0.002926753368228674\n",
      "Epoch: 463, Loss: 4.2671599658206105e-05\n",
      "Epoch: 464, Loss: 0.13694383203983307\n",
      "Epoch: 465, Loss: 0.00912423338741064\n",
      "Epoch: 466, Loss: 6.924779881956056e-05\n",
      "Epoch: 467, Loss: 0.012564515694975853\n",
      "Epoch: 468, Loss: 0.00018107271171174943\n",
      "Epoch: 469, Loss: 0.00010950299474643543\n",
      "Epoch: 470, Loss: 0.002751830266788602\n",
      "Epoch: 471, Loss: 0.0020043335389345884\n",
      "Epoch: 472, Loss: 0.011081005446612835\n",
      "Epoch: 473, Loss: 0.019338887184858322\n",
      "Epoch: 474, Loss: 9.364360448671505e-05\n",
      "Epoch: 475, Loss: 0.0009072559769265354\n",
      "Epoch: 476, Loss: 0.006623842753469944\n",
      "Epoch: 477, Loss: 0.008715972304344177\n",
      "Epoch: 478, Loss: 0.0030601955950260162\n",
      "Epoch: 479, Loss: 7.791835741954856e-06\n",
      "Epoch: 480, Loss: 0.0004649656475521624\n",
      "Epoch: 481, Loss: 0.0019067394314333797\n",
      "Epoch: 482, Loss: 0.03207564726471901\n",
      "Epoch: 483, Loss: 2.1952850147499703e-05\n",
      "Epoch: 484, Loss: 0.030037811025977135\n",
      "Epoch: 485, Loss: 0.015603884123265743\n",
      "Epoch: 486, Loss: 0.0036748559214174747\n",
      "Epoch: 487, Loss: 0.0009320829412899911\n",
      "Epoch: 488, Loss: 0.011210666038095951\n",
      "Epoch: 489, Loss: 0.010286620818078518\n",
      "Epoch: 490, Loss: 0.0013745104661211371\n",
      "Epoch: 491, Loss: 0.010711398907005787\n",
      "Epoch: 492, Loss: 0.0009274953627027571\n",
      "Epoch: 493, Loss: 1.1453696970420424e-05\n",
      "Epoch: 494, Loss: 0.03320718929171562\n",
      "Epoch: 495, Loss: 0.2141505777835846\n",
      "Epoch: 496, Loss: 0.0006547699449583888\n",
      "Epoch: 497, Loss: 3.514512354740873e-05\n",
      "Epoch: 498, Loss: 0.003011044580489397\n",
      "Epoch: 499, Loss: 2.462696829752531e-05\n",
      "Epoch: 500, Loss: 0.002063777530565858\n",
      "Epoch: 501, Loss: 0.02847207896411419\n",
      "Epoch: 502, Loss: 3.9406181713275146e-06\n",
      "Epoch: 503, Loss: 0.014993325807154179\n",
      "Epoch: 504, Loss: 9.569182293489575e-05\n",
      "Epoch: 505, Loss: 1.0655262485670391e-05\n",
      "Epoch: 506, Loss: 0.06474815309047699\n",
      "Epoch: 507, Loss: 0.0657704696059227\n",
      "Epoch: 508, Loss: 2.94424285129935e-06\n",
      "Epoch: 509, Loss: 0.0002687184023670852\n",
      "Epoch: 510, Loss: 0.0011538375401869416\n",
      "Epoch: 511, Loss: 0.0008014584891498089\n",
      "Epoch: 512, Loss: 0.00018914825341198593\n",
      "Epoch: 513, Loss: 0.01311457622796297\n",
      "Epoch: 514, Loss: 0.021252328529953957\n",
      "Epoch: 515, Loss: 0.00015702347445767373\n",
      "Epoch: 516, Loss: 0.0009280918748117983\n",
      "Epoch: 517, Loss: 3.8704405596945435e-05\n",
      "Epoch: 518, Loss: 4.4671127398032695e-05\n",
      "Epoch: 519, Loss: 0.01225882489234209\n",
      "Epoch: 520, Loss: 0.0001009988845908083\n",
      "Epoch: 521, Loss: 1.905160206661094e-05\n",
      "Epoch: 522, Loss: 0.0005246812361292541\n",
      "Epoch: 523, Loss: 0.0001288384955842048\n",
      "Epoch: 524, Loss: 0.04708923026919365\n",
      "Epoch: 525, Loss: 3.3823289413703606e-05\n",
      "Epoch: 526, Loss: 0.00015575122961308807\n",
      "Epoch: 527, Loss: 0.017042886465787888\n",
      "Epoch: 528, Loss: 0.00012408358452375978\n",
      "Epoch: 529, Loss: 5.4609849939879496e-06\n",
      "Epoch: 530, Loss: 0.017940238118171692\n",
      "Epoch: 531, Loss: 0.004762415308505297\n",
      "Epoch: 532, Loss: 0.011422278359532356\n",
      "Epoch: 533, Loss: 0.00012578416499309242\n",
      "Epoch: 534, Loss: 0.014428826980292797\n",
      "Epoch: 535, Loss: 0.13451780378818512\n",
      "Epoch: 536, Loss: 0.00016339260037057102\n",
      "Epoch: 537, Loss: 0.0003081569157075137\n",
      "Epoch: 538, Loss: 0.0017714668065309525\n",
      "Epoch: 539, Loss: 0.01046744454652071\n",
      "Epoch: 540, Loss: 0.002662939950823784\n",
      "Epoch: 541, Loss: 0.0026424434036016464\n",
      "Epoch: 542, Loss: 1.5793579223100096e-05\n",
      "Epoch: 543, Loss: 0.011466415598988533\n",
      "Epoch: 544, Loss: 0.0031108970288187265\n",
      "Epoch: 545, Loss: 0.0026167414616793394\n",
      "Epoch: 546, Loss: 0.0009298510849475861\n",
      "Epoch: 547, Loss: 4.453500150702894e-05\n",
      "Epoch: 548, Loss: 0.00018916628323495388\n",
      "Epoch: 549, Loss: 0.00011499797983560711\n",
      "Epoch: 550, Loss: 0.0005936712841503322\n",
      "Epoch: 551, Loss: 0.008442039601504803\n",
      "Epoch: 552, Loss: 0.003959969617426395\n",
      "Epoch: 553, Loss: 0.006355360150337219\n",
      "Epoch: 554, Loss: 1.7845168258645572e-05\n",
      "Epoch: 555, Loss: 0.0018676042091101408\n",
      "Epoch: 556, Loss: 5.8269997680326924e-05\n",
      "Epoch: 557, Loss: 0.011686264537274837\n",
      "Epoch: 558, Loss: 0.0009622641955502331\n",
      "Epoch: 559, Loss: 5.9137244534213096e-05\n",
      "Epoch: 560, Loss: 4.623779204848688e-06\n",
      "Epoch: 561, Loss: 0.015608604066073895\n",
      "Epoch: 562, Loss: 0.032596927136182785\n",
      "Epoch: 563, Loss: 0.0003784536093007773\n",
      "Epoch: 564, Loss: 0.007139432709664106\n",
      "Epoch: 565, Loss: 0.002793746069073677\n",
      "Epoch: 566, Loss: 2.185919765906874e-05\n",
      "Epoch: 567, Loss: 0.00736270984634757\n",
      "Epoch: 568, Loss: 0.0046860771253705025\n",
      "Epoch: 569, Loss: 0.0008798774215392768\n",
      "Epoch: 570, Loss: 0.004933793563395739\n",
      "Epoch: 571, Loss: 0.0027186055667698383\n",
      "Epoch: 572, Loss: 0.014036019332706928\n",
      "Epoch: 573, Loss: 0.15921442210674286\n",
      "Epoch: 574, Loss: 0.00028061019838787615\n",
      "Epoch: 575, Loss: 5.553030405280879e-06\n",
      "Epoch: 576, Loss: 0.0008855320629663765\n",
      "Epoch: 577, Loss: 0.005616273730993271\n",
      "Epoch: 578, Loss: 0.0026041583623737097\n",
      "Epoch: 579, Loss: 0.0007737443083897233\n",
      "Epoch: 580, Loss: 0.007189328782260418\n",
      "Epoch: 581, Loss: 0.00030817053630016744\n",
      "Epoch: 582, Loss: 0.0004952842136844993\n",
      "Epoch: 583, Loss: 0.002282836241647601\n",
      "Epoch: 584, Loss: 0.009465082548558712\n",
      "Epoch: 585, Loss: 0.041781723499298096\n",
      "Epoch: 586, Loss: 2.054450533250929e-06\n",
      "Epoch: 587, Loss: 1.6933596270973794e-05\n",
      "Epoch: 588, Loss: 2.8441863832995296e-05\n",
      "Epoch: 589, Loss: 0.01059461198747158\n",
      "Epoch: 590, Loss: 0.010004120878875256\n",
      "Epoch: 591, Loss: 0.001399640692397952\n",
      "Epoch: 592, Loss: 0.026154395192861557\n",
      "Epoch: 593, Loss: 0.0020723571069538593\n",
      "Epoch: 594, Loss: 0.008465033955872059\n",
      "Epoch: 595, Loss: 0.0008416113560087979\n",
      "Epoch: 596, Loss: 3.7177228477958124e-06\n",
      "Epoch: 597, Loss: 0.0014496296644210815\n",
      "Epoch: 598, Loss: 1.2239598618180025e-05\n",
      "Epoch: 599, Loss: 0.00023432391753885895\n",
      "Epoch: 600, Loss: 0.00021769532759208232\n",
      "Epoch: 601, Loss: 0.003695770399644971\n",
      "Epoch: 602, Loss: 2.8823180855397368e-06\n",
      "Epoch: 603, Loss: 0.0009423922747373581\n",
      "Epoch: 604, Loss: 0.0008504108409397304\n",
      "Epoch: 605, Loss: 0.009443612769246101\n",
      "Epoch: 606, Loss: 0.015406182035803795\n",
      "Epoch: 607, Loss: 0.0016551102744415402\n",
      "Epoch: 608, Loss: 0.0014680286403745413\n",
      "Epoch: 609, Loss: 3.5007822418720025e-08\n",
      "Epoch: 610, Loss: 2.42464784605545e-06\n",
      "Epoch: 611, Loss: 0.012132394127547741\n",
      "Epoch: 612, Loss: 0.0024641321506351233\n",
      "Epoch: 613, Loss: 0.0012944414047524333\n",
      "Epoch: 614, Loss: 4.031057414977113e-06\n",
      "Epoch: 615, Loss: 0.003128042910248041\n",
      "Epoch: 616, Loss: 0.0008773805457167327\n",
      "Epoch: 617, Loss: 0.0014303780626505613\n",
      "Epoch: 618, Loss: 0.0003880114236380905\n",
      "Epoch: 619, Loss: 2.1321877596847116e-08\n",
      "Epoch: 620, Loss: 0.001404688460752368\n",
      "Epoch: 621, Loss: 2.3886340727585775e-07\n",
      "Epoch: 622, Loss: 0.00211023329757154\n",
      "Epoch: 623, Loss: 7.181894761743024e-05\n",
      "Epoch: 624, Loss: 6.633073098782916e-06\n",
      "Epoch: 625, Loss: 0.010687602683901787\n",
      "Epoch: 626, Loss: 0.0008483351557515562\n",
      "Epoch: 627, Loss: 0.1313125491142273\n",
      "Epoch: 628, Loss: 0.009398100897669792\n",
      "Epoch: 629, Loss: 0.0016432054108008742\n",
      "Epoch: 630, Loss: 7.944603908072168e-07\n",
      "Epoch: 631, Loss: 0.0003400947025511414\n",
      "Epoch: 632, Loss: 0.010410318151116371\n",
      "Epoch: 633, Loss: 0.11995397508144379\n",
      "Epoch: 634, Loss: 0.0009005265892483294\n",
      "Epoch: 635, Loss: 1.0417725206934847e-05\n",
      "Epoch: 636, Loss: 0.0034429505467414856\n",
      "Epoch: 637, Loss: 8.008774602785707e-05\n",
      "Epoch: 638, Loss: 0.0006848796620033681\n",
      "Epoch: 639, Loss: 0.002314943354576826\n",
      "Epoch: 640, Loss: 1.4819491298112553e-05\n",
      "Epoch: 641, Loss: 2.5687433662824333e-05\n",
      "Epoch: 642, Loss: 0.01131456345319748\n",
      "Epoch: 643, Loss: 0.0016544511308893561\n",
      "Epoch: 644, Loss: 0.0007944327080622315\n",
      "Epoch: 645, Loss: 0.00020403492089826614\n",
      "Epoch: 646, Loss: 0.0014014954213052988\n",
      "Epoch: 647, Loss: 0.00045902488636784256\n",
      "Epoch: 648, Loss: 8.966157474787906e-05\n",
      "Epoch: 649, Loss: 0.009171047247946262\n",
      "Epoch: 650, Loss: 0.008262750692665577\n",
      "Epoch: 651, Loss: 0.0003078973386436701\n",
      "Epoch: 652, Loss: 0.001278166426345706\n",
      "Epoch: 653, Loss: 2.481858609826304e-05\n",
      "Epoch: 654, Loss: 0.0073473514057695866\n",
      "Epoch: 655, Loss: 0.00043133157305419445\n",
      "Epoch: 656, Loss: 6.066803325666115e-05\n",
      "Epoch: 657, Loss: 0.0012879347195848823\n",
      "Epoch: 658, Loss: 0.0009114159038290381\n",
      "Epoch: 659, Loss: 6.424698221962899e-05\n",
      "Epoch: 660, Loss: 3.914281933248276e-06\n",
      "Epoch: 661, Loss: 0.0007093236781656742\n",
      "Epoch: 662, Loss: 0.002582840621471405\n",
      "Epoch: 663, Loss: 0.03847608342766762\n",
      "Epoch: 664, Loss: 1.7049793314072303e-05\n",
      "Epoch: 665, Loss: 0.00032923821709118783\n",
      "Epoch: 666, Loss: 0.0008045142749324441\n",
      "Epoch: 667, Loss: 5.812790391246381e-07\n",
      "Epoch: 668, Loss: 0.0006083662738092244\n",
      "Epoch: 669, Loss: 0.00023743591737002134\n",
      "Epoch: 670, Loss: 0.00017075125651899725\n",
      "Epoch: 671, Loss: 0.002342620864510536\n",
      "Epoch: 672, Loss: 6.495972684206208e-06\n",
      "Epoch: 673, Loss: 7.471539720427245e-05\n",
      "Epoch: 674, Loss: 0.0017733921995386481\n",
      "Epoch: 675, Loss: 0.005855694878846407\n",
      "Epoch: 676, Loss: 0.006870665121823549\n",
      "Epoch: 677, Loss: 0.0007026538951322436\n",
      "Epoch: 678, Loss: 8.265720680356026e-06\n",
      "Epoch: 679, Loss: 0.006109574344009161\n",
      "Epoch: 680, Loss: 0.03313889726996422\n",
      "Epoch: 681, Loss: 9.235351899405941e-05\n",
      "Epoch: 682, Loss: 0.007958020083606243\n",
      "Epoch: 683, Loss: 0.0030476555693894625\n",
      "Epoch: 684, Loss: 0.0005488534807227552\n",
      "Epoch: 685, Loss: 0.009033448994159698\n",
      "Epoch: 686, Loss: 0.005570779088884592\n",
      "Epoch: 687, Loss: 0.0027309011202305555\n",
      "Epoch: 688, Loss: 1.0481134268047754e-05\n",
      "Epoch: 689, Loss: 0.003055475652217865\n",
      "Epoch: 690, Loss: 0.0007135618361644447\n",
      "Epoch: 691, Loss: 1.1565837212401675e-06\n",
      "Epoch: 692, Loss: 0.003254193114116788\n",
      "Epoch: 693, Loss: 0.0047341021709144115\n",
      "Epoch: 694, Loss: 0.015140960924327374\n",
      "Epoch: 695, Loss: 0.0005470020696520805\n",
      "Epoch: 696, Loss: 6.361944997479441e-06\n",
      "Epoch: 697, Loss: 7.00625023455359e-05\n",
      "Epoch: 698, Loss: 5.622582830255851e-05\n",
      "Epoch: 699, Loss: 0.01901167444884777\n",
      "Epoch: 700, Loss: 1.0038863820227562e-06\n",
      "Epoch: 701, Loss: 9.107349114856333e-07\n",
      "Epoch: 702, Loss: 0.0006849084747955203\n",
      "Epoch: 703, Loss: 0.005544469691812992\n",
      "Epoch: 704, Loss: 6.161818600958213e-05\n",
      "Epoch: 705, Loss: 5.3299467253964394e-05\n",
      "Epoch: 706, Loss: 0.11231458932161331\n",
      "Epoch: 707, Loss: 8.872488979250193e-05\n",
      "Epoch: 708, Loss: 0.02425059676170349\n",
      "Epoch: 709, Loss: 0.002480007242411375\n",
      "Epoch: 710, Loss: 1.0898848813667428e-05\n",
      "Epoch: 711, Loss: 5.494087599799968e-05\n",
      "Epoch: 712, Loss: 0.00010602791735436767\n",
      "Epoch: 713, Loss: 0.0009659170755185187\n",
      "Epoch: 714, Loss: 0.010665498673915863\n",
      "Epoch: 715, Loss: 6.293168553384021e-06\n",
      "Epoch: 716, Loss: 9.15303644433152e-06\n",
      "Epoch: 717, Loss: 0.0005098435212858021\n",
      "Epoch: 718, Loss: 0.0010507699334993958\n",
      "Epoch: 719, Loss: 0.0015067409258335829\n",
      "Epoch: 720, Loss: 2.046465397143038e-06\n",
      "Epoch: 721, Loss: 0.007820668630301952\n",
      "Epoch: 722, Loss: 0.003703347174450755\n",
      "Epoch: 723, Loss: 0.0005591338267549872\n",
      "Epoch: 724, Loss: 0.0005805320688523352\n",
      "Epoch: 725, Loss: 0.025147823616862297\n",
      "Epoch: 726, Loss: 0.0001901998184621334\n",
      "Epoch: 727, Loss: 0.03384709730744362\n",
      "Epoch: 728, Loss: 0.00018957947031594813\n",
      "Epoch: 729, Loss: 0.0018858526600524783\n",
      "Epoch: 730, Loss: 2.724727323766274e-07\n",
      "Epoch: 731, Loss: 0.009452147409319878\n",
      "Epoch: 732, Loss: 5.329795840225415e-06\n",
      "Epoch: 733, Loss: 0.0013815301936119795\n",
      "Epoch: 734, Loss: 0.00014516685041598976\n",
      "Epoch: 735, Loss: 9.982976735045668e-06\n",
      "Epoch: 736, Loss: 3.7013221572124166e-06\n",
      "Epoch: 737, Loss: 0.00406578928232193\n",
      "Epoch: 738, Loss: 0.0009282119572162628\n",
      "Epoch: 739, Loss: 4.9825837777461857e-05\n",
      "Epoch: 740, Loss: 0.008656986057758331\n",
      "Epoch: 741, Loss: 0.010029430501163006\n",
      "Epoch: 742, Loss: 0.01004585437476635\n",
      "Epoch: 743, Loss: 1.8784461644827388e-05\n",
      "Epoch: 744, Loss: 4.8143228923436254e-06\n",
      "Epoch: 745, Loss: 2.2037022517906735e-06\n",
      "Epoch: 746, Loss: 5.331592547008768e-05\n",
      "Epoch: 747, Loss: 0.00016140709340106696\n",
      "Epoch: 748, Loss: 0.0003461719024926424\n",
      "Epoch: 749, Loss: 0.0018077499698847532\n",
      "Epoch: 750, Loss: 0.0016718019032850862\n",
      "Epoch: 751, Loss: 0.0025474398862570524\n",
      "Epoch: 752, Loss: 6.423406739486381e-05\n",
      "Epoch: 753, Loss: 0.0026600584387779236\n",
      "Epoch: 754, Loss: 2.0182162643322954e-06\n",
      "Epoch: 755, Loss: 6.675714394077659e-05\n",
      "Epoch: 756, Loss: 0.004978336859494448\n",
      "Epoch: 757, Loss: 0.00024167541414499283\n",
      "Epoch: 758, Loss: 4.389808964333497e-05\n",
      "Epoch: 759, Loss: 2.6611884095473215e-05\n",
      "Epoch: 760, Loss: 0.0010952462907880545\n",
      "Epoch: 761, Loss: 7.15148780727759e-05\n",
      "Epoch: 762, Loss: 0.029033413156867027\n",
      "Epoch: 763, Loss: 0.004915288183838129\n",
      "Epoch: 764, Loss: 5.291224078973755e-05\n",
      "Epoch: 765, Loss: 8.3071572589688e-06\n",
      "Epoch: 766, Loss: 0.001213938812725246\n",
      "Epoch: 767, Loss: 1.0513880624785088e-05\n",
      "Epoch: 768, Loss: 1.7055247880648494e-08\n",
      "Epoch: 769, Loss: 7.321241923818889e-07\n",
      "Epoch: 770, Loss: 0.004748391918838024\n",
      "Epoch: 771, Loss: 0.006158036645501852\n",
      "Epoch: 772, Loss: 4.5964883611304685e-05\n",
      "Epoch: 773, Loss: 1.2217453331686556e-05\n",
      "Epoch: 774, Loss: 0.00013458059402182698\n",
      "Epoch: 775, Loss: 0.0010901394998654723\n",
      "Epoch: 776, Loss: 0.0015346527798101306\n",
      "Epoch: 777, Loss: 0.0027258049231022596\n",
      "Epoch: 778, Loss: 0.002873613266274333\n",
      "Epoch: 779, Loss: 3.2271325380861526e-06\n",
      "Epoch: 780, Loss: 0.0005562430014833808\n",
      "Epoch: 781, Loss: 0.00025984301464632154\n",
      "Epoch: 782, Loss: 0.001945585128851235\n",
      "Epoch: 783, Loss: 0.001104410388506949\n",
      "Epoch: 784, Loss: 0.0016807791544124484\n",
      "Epoch: 785, Loss: 0.0020656383130699396\n",
      "Epoch: 786, Loss: 0.004405290819704533\n",
      "Epoch: 787, Loss: 0.007485671900212765\n",
      "Epoch: 788, Loss: 0.0011887867003679276\n",
      "Epoch: 789, Loss: 0.0004901025677099824\n",
      "Epoch: 790, Loss: 0.00856815930455923\n",
      "Epoch: 791, Loss: 3.310951797175221e-05\n",
      "Epoch: 792, Loss: 0.026788046583533287\n",
      "Epoch: 793, Loss: 0.0012321078684180975\n",
      "Epoch: 794, Loss: 6.8302199451864e-08\n",
      "Epoch: 795, Loss: 6.7130636125511955e-06\n",
      "Epoch: 796, Loss: 0.0005980202695354819\n",
      "Epoch: 797, Loss: 4.038552106067073e-06\n",
      "Epoch: 798, Loss: 3.105286668869667e-05\n",
      "Epoch: 799, Loss: 0.0015203605871647596\n",
      "Epoch: 800, Loss: 7.310999535548035e-06\n",
      "Epoch: 801, Loss: 0.022531092166900635\n",
      "Epoch: 802, Loss: 4.027816373763926e-07\n",
      "Epoch: 803, Loss: 1.9551897878500313e-07\n",
      "Epoch: 804, Loss: 0.004552244674414396\n",
      "Epoch: 805, Loss: 1.8850554397431551e-06\n",
      "Epoch: 806, Loss: 0.019512251019477844\n",
      "Epoch: 807, Loss: 0.10161561518907547\n",
      "Epoch: 808, Loss: 0.10490549355745316\n",
      "Epoch: 809, Loss: 0.005471179727464914\n",
      "Epoch: 810, Loss: 0.0004184986755717546\n",
      "Epoch: 811, Loss: 0.008842804469168186\n",
      "Epoch: 812, Loss: 0.0008522135321982205\n",
      "Epoch: 813, Loss: 0.0016381144523620605\n",
      "Epoch: 814, Loss: 9.514753401163034e-06\n",
      "Epoch: 815, Loss: 0.01818952150642872\n",
      "Epoch: 816, Loss: 0.0014214749680832028\n",
      "Epoch: 817, Loss: 0.00036571716191247106\n",
      "Epoch: 818, Loss: 0.00018571452528703958\n",
      "Epoch: 819, Loss: 0.002157973125576973\n",
      "Epoch: 820, Loss: 0.001635809545405209\n",
      "Epoch: 821, Loss: 0.02293604239821434\n",
      "Epoch: 822, Loss: 0.005564243998378515\n",
      "Epoch: 823, Loss: 0.02023710496723652\n",
      "Epoch: 824, Loss: 0.00870185811072588\n",
      "Epoch: 825, Loss: 0.01544135995209217\n",
      "Epoch: 826, Loss: 4.0456605347571895e-05\n",
      "Epoch: 827, Loss: 1.364523541269591e-05\n",
      "Epoch: 828, Loss: 0.00028398033464327455\n",
      "Epoch: 829, Loss: 0.0006576244486495852\n",
      "Epoch: 830, Loss: 0.0005025544087402523\n",
      "Epoch: 831, Loss: 0.007649157661944628\n",
      "Epoch: 832, Loss: 0.0013896723976358771\n",
      "Epoch: 833, Loss: 0.013204261660575867\n",
      "Epoch: 834, Loss: 7.187025858002016e-06\n",
      "Epoch: 835, Loss: 0.09308674186468124\n",
      "Epoch: 836, Loss: 0.0005193333490751684\n",
      "Epoch: 837, Loss: 4.5712000428466126e-05\n",
      "Epoch: 838, Loss: 0.006989318411797285\n",
      "Epoch: 839, Loss: 0.0012806440936401486\n",
      "Epoch: 840, Loss: 0.0023643069434911013\n",
      "Epoch: 841, Loss: 1.357178007310722e-05\n",
      "Epoch: 842, Loss: 0.0036541225854307413\n",
      "Epoch: 843, Loss: 0.011769190430641174\n",
      "Epoch: 844, Loss: 0.010001158341765404\n",
      "Epoch: 845, Loss: 0.006196099799126387\n",
      "Epoch: 846, Loss: 0.007149137556552887\n",
      "Epoch: 847, Loss: 1.7818265973801317e-07\n",
      "Epoch: 848, Loss: 0.019143175333738327\n",
      "Epoch: 849, Loss: 2.7254556698608212e-05\n",
      "Epoch: 850, Loss: 0.00013857216981705278\n",
      "Epoch: 851, Loss: 0.0017483806004747748\n",
      "Epoch: 852, Loss: 0.006169763393700123\n",
      "Epoch: 853, Loss: 0.00129055290017277\n",
      "Epoch: 854, Loss: 3.9160732967502554e-07\n",
      "Epoch: 855, Loss: 0.0006339963292703032\n",
      "Epoch: 856, Loss: 0.023557154461741447\n",
      "Epoch: 857, Loss: 0.0006990350666455925\n",
      "Epoch: 858, Loss: 0.00027032147045247257\n",
      "Epoch: 859, Loss: 0.004944256506860256\n",
      "Epoch: 860, Loss: 6.912544563419942e-07\n",
      "Epoch: 861, Loss: 0.0009650340070948005\n",
      "Epoch: 862, Loss: 0.006187932100147009\n",
      "Epoch: 863, Loss: 0.0007067046244628727\n",
      "Epoch: 864, Loss: 0.01693238690495491\n",
      "Epoch: 865, Loss: 0.003988736774772406\n",
      "Epoch: 866, Loss: 0.007521091960370541\n",
      "Epoch: 867, Loss: 0.0002102261787513271\n",
      "Epoch: 868, Loss: 0.0068750581704080105\n",
      "Epoch: 869, Loss: 3.104532197539811e-06\n",
      "Epoch: 870, Loss: 0.0010047078831121325\n",
      "Epoch: 871, Loss: 1.1782241244873148e-06\n",
      "Epoch: 872, Loss: 0.019322901964187622\n",
      "Epoch: 873, Loss: 2.49493259616429e-05\n",
      "Epoch: 874, Loss: 1.866649472503923e-05\n",
      "Epoch: 875, Loss: 0.0007005664519965649\n",
      "Epoch: 876, Loss: 0.0007079858332872391\n",
      "Epoch: 877, Loss: 0.00010387166548753157\n",
      "Epoch: 878, Loss: 0.0002605619956739247\n",
      "Epoch: 879, Loss: 0.0007660718983970582\n",
      "Epoch: 880, Loss: 9.01807434274815e-05\n",
      "Epoch: 881, Loss: 1.8029483328518836e-07\n",
      "Epoch: 882, Loss: 0.0006869194330647588\n",
      "Epoch: 883, Loss: 0.0003571546985767782\n",
      "Epoch: 884, Loss: 0.00110817130189389\n",
      "Epoch: 885, Loss: 0.001131719327531755\n",
      "Epoch: 886, Loss: 6.472554377978668e-05\n",
      "Epoch: 887, Loss: 6.832357757957652e-05\n",
      "Epoch: 888, Loss: 0.050472162663936615\n",
      "Epoch: 889, Loss: 9.132222476182505e-05\n",
      "Epoch: 890, Loss: 0.0003275099734310061\n",
      "Epoch: 891, Loss: 4.0408676227343676e-07\n",
      "Epoch: 892, Loss: 6.29835949439439e-06\n",
      "Epoch: 893, Loss: 0.0006463088211603463\n",
      "Epoch: 894, Loss: 0.003870483720675111\n",
      "Epoch: 895, Loss: 0.0007847538217902184\n",
      "Epoch: 896, Loss: 0.0007572007598355412\n",
      "Epoch: 897, Loss: 0.00265757879242301\n",
      "Epoch: 898, Loss: 1.0199634061791585e-06\n",
      "Epoch: 899, Loss: 0.0011124737793579698\n",
      "Epoch: 900, Loss: 0.0008333060541190207\n",
      "Epoch: 901, Loss: 8.300861372845247e-05\n",
      "Epoch: 902, Loss: 0.07522804290056229\n",
      "Epoch: 903, Loss: 1.202781277243048e-05\n",
      "Epoch: 904, Loss: 0.0026933508925139904\n",
      "Epoch: 905, Loss: 2.8246660804143175e-05\n",
      "Epoch: 906, Loss: 0.00105690595228225\n",
      "Epoch: 907, Loss: 0.001926279510371387\n",
      "Epoch: 908, Loss: 7.354448371188482e-06\n",
      "Epoch: 909, Loss: 0.000997096416540444\n",
      "Epoch: 910, Loss: 9.858718840405345e-06\n",
      "Epoch: 911, Loss: 4.131300556764472e-06\n",
      "Epoch: 912, Loss: 2.3725078790448606e-06\n",
      "Epoch: 913, Loss: 5.303887178342848e-07\n",
      "Epoch: 914, Loss: 0.0012473089154809713\n",
      "Epoch: 915, Loss: 3.4385659091640264e-05\n",
      "Epoch: 916, Loss: 0.00036187469959259033\n",
      "Epoch: 917, Loss: 0.007371001876890659\n",
      "Epoch: 918, Loss: 0.0007614657515659928\n",
      "Epoch: 919, Loss: 0.00018349940364714712\n",
      "Epoch: 920, Loss: 2.6813837394001894e-05\n",
      "Epoch: 921, Loss: 2.0129689346504165e-06\n",
      "Epoch: 922, Loss: 0.0048011294566094875\n",
      "Epoch: 923, Loss: 4.982553218724206e-05\n",
      "Epoch: 924, Loss: 1.095312927645864e-05\n",
      "Epoch: 925, Loss: 7.657344394829124e-05\n",
      "Epoch: 926, Loss: 1.5252513207997254e-07\n",
      "Epoch: 927, Loss: 0.0001630153419682756\n",
      "Epoch: 928, Loss: 0.00031297956593334675\n",
      "Epoch: 929, Loss: 0.00022739064297638834\n",
      "Epoch: 930, Loss: 7.030404503893806e-06\n",
      "Epoch: 931, Loss: 0.002173636807128787\n",
      "Epoch: 932, Loss: 0.00027381774270907044\n",
      "Epoch: 933, Loss: 0.019507307559251785\n",
      "Epoch: 934, Loss: 8.28386764624156e-05\n",
      "Epoch: 935, Loss: 2.7967815185547806e-05\n",
      "Epoch: 936, Loss: 1.1658678886306006e-05\n",
      "Epoch: 937, Loss: 0.0007976071210578084\n",
      "Epoch: 938, Loss: 0.0008614665712229908\n",
      "Epoch: 939, Loss: 7.399454625556245e-05\n",
      "Epoch: 940, Loss: 1.3736309938394697e-06\n",
      "Epoch: 941, Loss: 0.00021339868544600904\n",
      "Epoch: 942, Loss: 1.951644298969768e-05\n",
      "Epoch: 943, Loss: 5.07955655848491e-06\n",
      "Epoch: 944, Loss: 0.0034103519283235073\n",
      "Epoch: 945, Loss: 0.00016736685938667506\n",
      "Epoch: 946, Loss: 0.003370254999026656\n",
      "Epoch: 947, Loss: 2.842979120032396e-05\n",
      "Epoch: 948, Loss: 3.922139057976892e-06\n",
      "Epoch: 949, Loss: 2.331114956177771e-06\n",
      "Epoch: 950, Loss: 0.003934355918318033\n",
      "Epoch: 951, Loss: 0.017667502164840698\n",
      "Epoch: 952, Loss: 2.3510337996413e-05\n",
      "Epoch: 953, Loss: 1.0272947292833123e-07\n",
      "Epoch: 954, Loss: 0.005898791365325451\n",
      "Epoch: 955, Loss: 0.00016047677490860224\n",
      "Epoch: 956, Loss: 0.0002195517299696803\n",
      "Epoch: 957, Loss: 0.015794195234775543\n",
      "Epoch: 958, Loss: 0.00027180270990356803\n",
      "Epoch: 959, Loss: 5.440982204163447e-05\n",
      "Epoch: 960, Loss: 5.005070852348581e-05\n",
      "Epoch: 961, Loss: 0.0032999760005623102\n",
      "Epoch: 962, Loss: 0.06350071728229523\n",
      "Epoch: 963, Loss: 2.0017467249999754e-05\n",
      "Epoch: 964, Loss: 9.56989242695272e-06\n",
      "Epoch: 965, Loss: 0.0033005629666149616\n",
      "Epoch: 966, Loss: 0.0005423611146397889\n",
      "Epoch: 967, Loss: 0.00047861362691037357\n",
      "Epoch: 968, Loss: 0.0029367113020271063\n",
      "Epoch: 969, Loss: 0.02119237370789051\n",
      "Epoch: 970, Loss: 0.0004166009312029928\n",
      "Epoch: 971, Loss: 0.009322905912995338\n",
      "Epoch: 972, Loss: 0.015547007322311401\n",
      "Epoch: 973, Loss: 0.0009721218375489116\n",
      "Epoch: 974, Loss: 1.973875214389409e-06\n",
      "Epoch: 975, Loss: 3.821226982836379e-06\n",
      "Epoch: 976, Loss: 0.0025757576804608107\n",
      "Epoch: 977, Loss: 6.441649475164013e-06\n",
      "Epoch: 978, Loss: 0.01779293827712536\n",
      "Epoch: 979, Loss: 0.0014436357887461782\n",
      "Epoch: 980, Loss: 0.0006559333996847272\n",
      "Epoch: 981, Loss: 0.005537031684070826\n",
      "Epoch: 982, Loss: 4.5700421651417855e-06\n",
      "Epoch: 983, Loss: 0.00023308144591283053\n",
      "Epoch: 984, Loss: 2.5197266950272024e-05\n",
      "Epoch: 985, Loss: 0.0001429308467777446\n",
      "Epoch: 986, Loss: 3.2472873954247916e-06\n",
      "Epoch: 987, Loss: 1.7720743983318243e-07\n",
      "Epoch: 988, Loss: 0.004620011895895004\n",
      "Epoch: 989, Loss: 0.0002728995168581605\n",
      "Epoch: 990, Loss: 0.0007236642413772643\n",
      "Epoch: 991, Loss: 0.00046671510790474713\n",
      "Epoch: 992, Loss: 4.556834028335288e-06\n",
      "Epoch: 993, Loss: 0.0007212960044853389\n",
      "Epoch: 994, Loss: 0.0038499883376061916\n",
      "Epoch: 995, Loss: 0.0029957660008221865\n",
      "Epoch: 996, Loss: 4.579831966111669e-06\n",
      "Epoch: 997, Loss: 1.3263179425848648e-06\n",
      "Epoch: 998, Loss: 0.06467104703187943\n",
      "Epoch: 999, Loss: 5.900041742279427e-06\n",
      "Epoch: 1000, Loss: 0.006516341120004654\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        y_pred = model(batch_features)\n",
    "        loss = loss_function(y_pred, batch_labels.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a75de744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6094\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.9).float()\n",
    "\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy: .4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
