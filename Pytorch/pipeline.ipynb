{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c743b7fc",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a73b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ebce492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42a5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['id', 'Unnamed: 32'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3bf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05964fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49bb3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c8307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train)\n",
    "x_test_tensor = torch.from_numpy(x_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f3e7d",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc483c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, x: torch.Tensor):\n",
    "        self.weights = torch.rand(x.shape[1], 1, dtype = torch.float64, requires_grad = True)\n",
    "        self.bias = torch.zeros(1, 1, dtype = torch.float64, requires_grad = True)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        z = torch.matmul(x, self.weights) + self.bias\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "    \n",
    "    def loss_function(self, y_pred: torch.Tensor, y: torch.Tensor):\n",
    "        #Clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = -(y* torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred)).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99e937",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93cd2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df6210",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00bb2e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7250061701931445\n",
      "Epoch: 2, Loss: 3.605434621710056\n",
      "Epoch: 3, Loss: 3.481513389996679\n",
      "Epoch: 4, Loss: 3.352395921611901\n",
      "Epoch: 5, Loss: 3.219366017972275\n",
      "Epoch: 6, Loss: 3.0828896762389375\n",
      "Epoch: 7, Loss: 2.941938937028931\n",
      "Epoch: 8, Loss: 2.7947137813291203\n",
      "Epoch: 9, Loss: 2.648121709999587\n",
      "Epoch: 10, Loss: 2.5013506724259997\n",
      "Epoch: 11, Loss: 2.3548032314361103\n",
      "Epoch: 12, Loss: 2.2064111544523453\n",
      "Epoch: 13, Loss: 2.0622824592859352\n",
      "Epoch: 14, Loss: 1.9232038985471407\n",
      "Epoch: 15, Loss: 1.7860976902565031\n",
      "Epoch: 16, Loss: 1.6565431140772702\n",
      "Epoch: 17, Loss: 1.5290427790506023\n",
      "Epoch: 18, Loss: 1.4112420534097343\n",
      "Epoch: 19, Loss: 1.3068914507265557\n",
      "Epoch: 20, Loss: 1.2167380432056665\n",
      "Epoch: 21, Loss: 1.140838561502456\n",
      "Epoch: 22, Loss: 1.0783158901197891\n",
      "Epoch: 23, Loss: 1.0274655711533978\n",
      "Epoch: 24, Loss: 0.986204270356751\n",
      "Epoch: 25, Loss: 0.9525251854754976\n",
      "Epoch: 26, Loss: 0.9247298543217285\n",
      "Epoch: 27, Loss: 0.9014693118654178\n",
      "Epoch: 28, Loss: 0.8817019590711965\n",
      "Epoch: 29, Loss: 0.8646339002258047\n",
      "Epoch: 30, Loss: 0.8496656128377092\n",
      "Epoch: 31, Loss: 0.836349086938181\n",
      "Epoch: 32, Loss: 0.8243535341163577\n",
      "Epoch: 33, Loss: 0.8134374043814728\n",
      "Epoch: 34, Loss: 0.8034254794414503\n",
      "Epoch: 35, Loss: 0.7941905182291102\n",
      "Epoch: 36, Loss: 0.7856390697197122\n",
      "Epoch: 37, Loss: 0.7777009349321332\n",
      "Epoch: 38, Loss: 0.7703216283620695\n",
      "Epoch: 39, Loss: 0.7634571614862101\n",
      "Epoch: 40, Loss: 0.7570705358288152\n",
      "Epoch: 41, Loss: 0.7511294445598347\n",
      "Epoch: 42, Loss: 0.7456048009732867\n",
      "Epoch: 43, Loss: 0.7404698177968818\n",
      "Epoch: 44, Loss: 0.7356994451636663\n",
      "Epoch: 45, Loss: 0.7312700372316572\n",
      "Epoch: 46, Loss: 0.7271591613413332\n",
      "Epoch: 47, Loss: 0.7233454935834146\n",
      "Epoch: 48, Loss: 0.7198087646535289\n",
      "Epoch: 49, Loss: 0.716529733020943\n",
      "Epoch: 50, Loss: 0.7134901710170808\n",
      "Epoch: 51, Loss: 0.7106728550329754\n",
      "Epoch: 52, Loss: 0.708061554651894\n",
      "Epoch: 53, Loss: 0.7056410179140808\n",
      "Epoch: 54, Loss: 0.7033969514495625\n",
      "Epoch: 55, Loss: 0.701315995199844\n",
      "Epoch: 56, Loss: 0.6993856920593114\n",
      "Epoch: 57, Loss: 0.6975944531206638\n",
      "Epoch: 58, Loss: 0.6959315193863008\n",
      "Epoch: 59, Loss: 0.6943869208657653\n",
      "Epoch: 60, Loss: 0.6929514339586685\n",
      "Epoch: 61, Loss: 0.6916165379524198\n",
      "Epoch: 62, Loss: 0.6903743713659469\n",
      "Epoch: 63, Loss: 0.6892176887596884\n",
      "Epoch: 64, Loss: 0.6881398185190873\n",
      "Epoch: 65, Loss: 0.6871346220106429\n",
      "Epoch: 66, Loss: 0.6861964544106306\n",
      "Epoch: 67, Loss: 0.6853201274191929\n",
      "Epoch: 68, Loss: 0.684500873997543\n",
      "Epoch: 69, Loss: 0.683734315203413\n",
      "Epoch: 70, Loss: 0.6830164291489143\n",
      "Epoch: 71, Loss: 0.6823435220645457\n",
      "Epoch: 72, Loss: 0.6817122014219447\n",
      "Epoch: 73, Loss: 0.6811193510447839\n",
      "Epoch: 74, Loss: 0.6805621081207123\n",
      "Epoch: 75, Loss: 0.6800378420162267\n",
      "Epoch: 76, Loss: 0.6795441347897977\n",
      "Epoch: 77, Loss: 0.6790787632955091\n",
      "Epoch: 78, Loss: 0.6786396827691418\n",
      "Epoch: 79, Loss: 0.6782250117903531\n",
      "Epoch: 80, Loss: 0.6778330185178373\n",
      "Epoch: 81, Loss: 0.6774621080986536\n",
      "Epoch: 82, Loss: 0.6771108111579196\n",
      "Epoch: 83, Loss: 0.6767777732805025\n",
      "Epoch: 84, Loss: 0.6764617454019963\n",
      "Epoch: 85, Loss: 0.676161575031964\n",
      "Epoch: 86, Loss: 0.6758761982380505\n",
      "Epoch: 87, Loss: 0.6756046323250171\n",
      "Epoch: 88, Loss: 0.6753459691479802\n",
      "Epoch: 89, Loss: 0.6750993690040875\n",
      "Epoch: 90, Loss: 0.6748640550515332\n",
      "Epoch: 91, Loss: 0.6746393082091678\n",
      "Epoch: 92, Loss: 0.6744244624940098\n",
      "Epoch: 93, Loss: 0.6742189007577153\n",
      "Epoch: 94, Loss: 0.6740220507865177\n",
      "Epoch: 95, Loss: 0.6738333817323189\n",
      "Epoch: 96, Loss: 0.6736524008455298\n",
      "Epoch: 97, Loss: 0.6734786504829132\n",
      "Epoch: 98, Loss: 0.6733117053661113\n",
      "Epoch: 99, Loss: 0.6731511700687526\n",
      "Epoch: 100, Loss: 0.6729966767120493\n",
      "Epoch: 101, Loss: 0.6728478828506226\n",
      "Epoch: 102, Loss: 0.6727044695319596\n",
      "Epoch: 103, Loss: 0.6725661395144197\n",
      "Epoch: 104, Loss: 0.6724326156300676\n",
      "Epoch: 105, Loss: 0.6723036392798671\n",
      "Epoch: 106, Loss: 0.6721789690498869\n",
      "Epoch: 107, Loss: 0.6720583794381959\n",
      "Epoch: 108, Loss: 0.6719416596830536\n",
      "Epoch: 109, Loss: 0.6718286126838388\n",
      "Epoch: 110, Loss: 0.6717190540069243\n",
      "Epoch: 111, Loss: 0.6716128109693964\n",
      "Epoch: 112, Loss: 0.6715097217941423\n",
      "Epoch: 113, Loss: 0.6714096348304045\n",
      "Epoch: 114, Loss: 0.671312407834409\n",
      "Epoch: 115, Loss: 0.6712179073051509\n",
      "Epoch: 116, Loss: 0.6711260078708419\n",
      "Epoch: 117, Loss: 0.6710365917219164\n",
      "Epoch: 118, Loss: 0.6709495480868402\n",
      "Epoch: 119, Loss: 0.6708647727472862\n",
      "Epoch: 120, Loss: 0.6707821675895416\n",
      "Epoch: 121, Loss: 0.6707016401892619\n",
      "Epoch: 122, Loss: 0.6706231034269412\n",
      "Epoch: 123, Loss: 0.6705464751316808\n",
      "Epoch: 124, Loss: 0.6704716777510461\n",
      "Epoch: 125, Loss: 0.670398638044975\n",
      "Epoch: 126, Loss: 0.6703272868018769\n",
      "Epoch: 127, Loss: 0.6702575585752126\n",
      "Epoch: 128, Loss: 0.6701893914389765\n",
      "Epoch: 129, Loss: 0.6701227267606458\n",
      "Epoch: 130, Loss: 0.6700575089902602\n",
      "Epoch: 131, Loss: 0.6699936854644145\n",
      "Epoch: 132, Loss: 0.6699312062240413\n",
      "Epoch: 133, Loss: 0.669870023844946\n",
      "Epoch: 134, Loss: 0.6698100932801436\n",
      "Epoch: 135, Loss: 0.6697513717131196\n",
      "Epoch: 136, Loss: 0.6696938184212041\n",
      "Epoch: 137, Loss: 0.6696373946483181\n",
      "Epoch: 138, Loss: 0.6695820634863986\n",
      "Epoch: 139, Loss: 0.6695277897648705\n",
      "Epoch: 140, Loss: 0.669474539947583\n",
      "Epoch: 141, Loss: 0.6694222820366628\n",
      "Epoch: 142, Loss: 0.6693709854827912\n",
      "Epoch: 143, Loss: 0.6693206211014402\n",
      "Epoch: 144, Loss: 0.6692711609946422\n",
      "Epoch: 145, Loss: 0.6692225784778995\n",
      "Epoch: 146, Loss: 0.6691748480118673\n",
      "Epoch: 147, Loss: 0.6691279451384762\n",
      "Epoch: 148, Loss: 0.6690818464211779\n",
      "Epoch: 149, Loss: 0.6690365293890277\n",
      "Epoch: 150, Loss: 0.6689919724843375\n",
      "Epoch: 151, Loss: 0.6689481550136469\n",
      "Epoch: 152, Loss: 0.6689050571017879\n",
      "Epoch: 153, Loss: 0.668862659648827\n",
      "Epoch: 154, Loss: 0.6688209442896883\n",
      "Epoch: 155, Loss: 0.6687798933562751\n",
      "Epoch: 156, Loss: 0.6687394898419194\n",
      "Epoch: 157, Loss: 0.6686997173680035\n",
      "Epoch: 158, Loss: 0.6686605601526034\n",
      "Epoch: 159, Loss: 0.6686220029810256\n",
      "Epoch: 160, Loss: 0.6685840311781011\n",
      "Epoch: 161, Loss: 0.6685466305821298\n",
      "Epoch: 162, Loss: 0.6685097875203598\n",
      "Epoch: 163, Loss: 0.6684734887859025\n",
      "Epoch: 164, Loss: 0.6684377216159892\n",
      "Epoch: 165, Loss: 0.6684024736714824\n",
      "Epoch: 166, Loss: 0.6683677330175599\n",
      "Epoch: 167, Loss: 0.6683334881054961\n",
      "Epoch: 168, Loss: 0.6682997277554691\n",
      "Epoch: 169, Loss: 0.6682664411403302\n",
      "Epoch: 170, Loss: 0.6682336177702727\n",
      "Epoch: 171, Loss: 0.6682012474783438\n",
      "Epoch: 172, Loss: 0.668169320406746\n",
      "Epoch: 173, Loss: 0.6681378269938806\n",
      "Epoch: 174, Loss: 0.6681067579620836\n",
      "Epoch: 175, Loss: 0.6680761043060147\n",
      "Epoch: 176, Loss: 0.6680458572816577\n",
      "Epoch: 177, Loss: 0.6680160083958938\n",
      "Epoch: 178, Loss: 0.6679865493966141\n",
      "Epoch: 179, Loss: 0.6679574722633406\n",
      "Epoch: 180, Loss: 0.66792876919832\n",
      "Epoch: 181, Loss: 0.6679004326180673\n",
      "Epoch: 182, Loss: 0.667872455145331\n",
      "Epoch: 183, Loss: 0.6678448296014506\n",
      "Epoch: 184, Loss: 0.6678175489990921\n",
      "Epoch: 185, Loss: 0.6677906065353306\n",
      "Epoch: 186, Loss: 0.6677639955850663\n",
      "Epoch: 187, Loss: 0.6677377096947503\n",
      "Epoch: 188, Loss: 0.667711742576406\n",
      "Epoch: 189, Loss: 0.667686088101927\n",
      "Epoch: 190, Loss: 0.6676607402976364\n",
      "Epoch: 191, Loss: 0.6676356933390947\n",
      "Epoch: 192, Loss: 0.6676109415461381\n",
      "Epoch: 193, Loss: 0.6675864793781406\n",
      "Epoch: 194, Loss: 0.6675623014294823\n",
      "Epoch: 195, Loss: 0.6675384024252142\n",
      "Epoch: 196, Loss: 0.6675147772169128\n",
      "Epoch: 197, Loss: 0.6674914207787066\n",
      "Epoch: 198, Loss: 0.6674683282034732\n",
      "Epoch: 199, Loss: 0.6674454946991933\n",
      "Epoch: 200, Loss: 0.6674229155854543\n",
      "Epoch: 201, Loss: 0.6674005862900971\n",
      "Epoch: 202, Loss: 0.6673785023459967\n",
      "Epoch: 203, Loss: 0.6673566593879724\n",
      "Epoch: 204, Loss: 0.6673350531498178\n",
      "Epoch: 205, Loss: 0.6673136794614474\n",
      "Epoch: 206, Loss: 0.6672925342461526\n",
      "Epoch: 207, Loss: 0.667271613517962\n",
      "Epoch: 208, Loss: 0.6672509133791006\n",
      "Epoch: 209, Loss: 0.6672304300175446\n",
      "Epoch: 210, Loss: 0.6672101597046642\n",
      "Epoch: 211, Loss: 0.667190098792954\n",
      "Epoch: 212, Loss: 0.6671702437138431\n",
      "Epoch: 213, Loss: 0.6671505909755856\n",
      "Epoch: 214, Loss: 0.6671311371612215\n",
      "Epoch: 215, Loss: 0.6671118789266116\n",
      "Epoch: 216, Loss: 0.6670928129985395\n",
      "Epoch: 217, Loss: 0.6670739361728767\n",
      "Epoch: 218, Loss: 0.6670552453128102\n",
      "Epoch: 219, Loss: 0.6670367373471296\n",
      "Epoch: 220, Loss: 0.6670184092685699\n",
      "Epoch: 221, Loss: 0.6670002581322081\n",
      "Epoch: 222, Loss: 0.6669822810539122\n",
      "Epoch: 223, Loss: 0.6669644752088392\n",
      "Epoch: 224, Loss: 0.66694683782998\n",
      "Epoch: 225, Loss: 0.6669293662067511\n",
      "Epoch: 226, Loss: 0.6669120576836288\n",
      "Epoch: 227, Loss: 0.6668949096588246\n",
      "Epoch: 228, Loss: 0.6668779195830026\n",
      "Epoch: 229, Loss: 0.6668610849580334\n",
      "Epoch: 230, Loss: 0.666844403335787\n",
      "Epoch: 231, Loss: 0.666827872316959\n",
      "Epoch: 232, Loss: 0.6668114895499332\n",
      "Epoch: 233, Loss: 0.666795252729675\n",
      "Epoch: 234, Loss: 0.6667791595966586\n",
      "Epoch: 235, Loss: 0.6667632079358228\n",
      "Epoch: 236, Loss: 0.6667473955755567\n",
      "Epoch: 237, Loss: 0.6667317203867145\n",
      "Epoch: 238, Loss: 0.6667161802816562\n",
      "Epoch: 239, Loss: 0.6667007732133154\n",
      "Epoch: 240, Loss: 0.6666854971742924\n",
      "Epoch: 241, Loss: 0.6666703501959709\n",
      "Epoch: 242, Loss: 0.6666553303476593\n",
      "Epoch: 243, Loss: 0.6666404357357548\n",
      "Epoch: 244, Loss: 0.6666256645029282\n",
      "Epoch: 245, Loss: 0.6666110148273304\n",
      "Epoch: 246, Loss: 0.6665964849218223\n",
      "Epoch: 247, Loss: 0.6665820730332188\n",
      "Epoch: 248, Loss: 0.666567777441557\n",
      "Epoch: 249, Loss: 0.6665535964593818\n",
      "Epoch: 250, Loss: 0.666539528431048\n",
      "Epoch: 251, Loss: 0.6665255717320404\n",
      "Epoch: 252, Loss: 0.6665117247683124\n",
      "Epoch: 253, Loss: 0.6664979859756387\n",
      "Epoch: 254, Loss: 0.6664843538189853\n",
      "Epoch: 255, Loss: 0.666470826791894\n",
      "Epoch: 256, Loss: 0.6664574034158829\n",
      "Epoch: 257, Loss: 0.6664440822398593\n",
      "Epoch: 258, Loss: 0.6664308618395492\n",
      "Epoch: 259, Loss: 0.6664177408169382\n",
      "Epoch: 260, Loss: 0.6664047177997275\n",
      "Epoch: 261, Loss: 0.6663917914408003\n",
      "Epoch: 262, Loss: 0.6663789604177033\n",
      "Epoch: 263, Loss: 0.6663662234321386\n",
      "Epoch: 264, Loss: 0.6663535792094677\n",
      "Epoch: 265, Loss: 0.666341026498227\n",
      "Epoch: 266, Loss: 0.6663285640696551\n",
      "Epoch: 267, Loss: 0.666316190717229\n",
      "Epoch: 268, Loss: 0.6663039052562135\n",
      "Epoch: 269, Loss: 0.6662917065232183\n",
      "Epoch: 270, Loss: 0.6662795933757664\n",
      "Epoch: 271, Loss: 0.6662675646918718\n",
      "Epoch: 272, Loss: 0.6662556193696275\n",
      "Epoch: 273, Loss: 0.6662437563268006\n",
      "Epoch: 274, Loss: 0.6662319745004385\n",
      "Epoch: 275, Loss: 0.6662202728464827\n",
      "Epoch: 276, Loss: 0.666208650339391\n",
      "Epoch: 277, Loss: 0.6661971059717693\n",
      "Epoch: 278, Loss: 0.666185638754009\n",
      "Epoch: 279, Loss: 0.6661742477139349\n",
      "Epoch: 280, Loss: 0.6661629318964584\n",
      "Epoch: 281, Loss: 0.6661516903632406\n",
      "Epoch: 282, Loss: 0.6661405221923601\n",
      "Epoch: 283, Loss: 0.6661294264779898\n",
      "Epoch: 284, Loss: 0.6661184023300805\n",
      "Epoch: 285, Loss: 0.6661074488740494\n",
      "Epoch: 286, Loss: 0.6660965652504778\n",
      "Epoch: 287, Loss: 0.6660857506148133\n",
      "Epoch: 288, Loss: 0.6660750041370797\n",
      "Epoch: 289, Loss: 0.6660643250015909\n",
      "Epoch: 290, Loss: 0.6660537124066735\n",
      "Epoch: 291, Loss: 0.6660431655643937\n",
      "Epoch: 292, Loss: 0.6660326837002897\n",
      "Epoch: 293, Loss: 0.6660222660531101\n",
      "Epoch: 294, Loss: 0.6660119118745584\n",
      "Epoch: 295, Loss: 0.6660016204290419\n",
      "Epoch: 296, Loss: 0.6659913909934254\n",
      "Epoch: 297, Loss: 0.6659812228567915\n",
      "Epoch: 298, Loss: 0.6659711153202053\n",
      "Epoch: 299, Loss: 0.6659610676964821\n",
      "Epoch: 300, Loss: 0.6659510793099637\n",
      "Epoch: 301, Loss: 0.6659411494962948\n",
      "Epoch: 302, Loss: 0.6659312776022078\n",
      "Epoch: 303, Loss: 0.6659214629853101\n",
      "Epoch: 304, Loss: 0.6659117050138753\n",
      "Epoch: 305, Loss: 0.6659020030666403\n",
      "Epoch: 306, Loss: 0.6658923565326049\n",
      "Epoch: 307, Loss: 0.6658827648108373\n",
      "Epoch: 308, Loss: 0.6658732273102814\n",
      "Epoch: 309, Loss: 0.6658637434495692\n",
      "Epoch: 310, Loss: 0.6658543126568371\n",
      "Epoch: 311, Loss: 0.6658449343695458\n",
      "Epoch: 312, Loss: 0.6658356080343036\n",
      "Epoch: 313, Loss: 0.6658263331066925\n",
      "Epoch: 314, Loss: 0.6658171090510999\n",
      "Epoch: 315, Loss: 0.6658079353405516\n",
      "Epoch: 316, Loss: 0.6657988114565493\n",
      "Epoch: 317, Loss: 0.6657897368889106\n",
      "Epoch: 318, Loss: 0.6657807111356131\n",
      "Epoch: 319, Loss: 0.6657717337026403\n",
      "Epoch: 320, Loss: 0.6657628041038326\n",
      "Epoch: 321, Loss: 0.6657539218607387\n",
      "Epoch: 322, Loss: 0.6657450865024722\n",
      "Epoch: 323, Loss: 0.6657362975655702\n",
      "Epoch: 324, Loss: 0.6657275545938535\n",
      "Epoch: 325, Loss: 0.6657188571382923\n",
      "Epoch: 326, Loss: 0.6657102047568715\n",
      "Epoch: 327, Loss: 0.6657015970144619\n",
      "Epoch: 328, Loss: 0.6656930334826896\n",
      "Epoch: 329, Loss: 0.6656845137398136\n",
      "Epoch: 330, Loss: 0.6656760373706004\n",
      "Epoch: 331, Loss: 0.6656676039662046\n",
      "Epoch: 332, Loss: 0.66565921312405\n",
      "Epoch: 333, Loss: 0.6656508644477147\n",
      "Epoch: 334, Loss: 0.6656425575468164\n",
      "Epoch: 335, Loss: 0.6656342920369024\n",
      "Epoch: 336, Loss: 0.6656260675393383\n",
      "Epoch: 337, Loss: 0.6656178836812032\n",
      "Epoch: 338, Loss: 0.6656097400951837\n",
      "Epoch: 339, Loss: 0.6656016364194706\n",
      "Epoch: 340, Loss: 0.665593572297659\n",
      "Epoch: 341, Loss: 0.6655855473786487\n",
      "Epoch: 342, Loss: 0.665577561316547\n",
      "Epoch: 343, Loss: 0.6655696137705748\n",
      "Epoch: 344, Loss: 0.6655617044049718\n",
      "Epoch: 345, Loss: 0.665553832888906\n",
      "Epoch: 346, Loss: 0.6655459988963843\n",
      "Epoch: 347, Loss: 0.6655382021061637\n",
      "Epoch: 348, Loss: 0.6655304422016658\n",
      "Epoch: 349, Loss: 0.665522718870892\n",
      "Epoch: 350, Loss: 0.6655150318063405\n",
      "Epoch: 351, Loss: 0.6655073807049254\n",
      "Epoch: 352, Loss: 0.6654997652678968\n",
      "Epoch: 353, Loss: 0.6654921852007623\n",
      "Epoch: 354, Loss: 0.665484640213211\n",
      "Epoch: 355, Loss: 0.6654771300190377\n",
      "Epoch: 356, Loss: 0.66546965433607\n",
      "Epoch: 357, Loss: 0.6654622128860945\n",
      "Epoch: 358, Loss: 0.665454805394788\n",
      "Epoch: 359, Loss: 0.6654474315916462\n",
      "Epoch: 360, Loss: 0.6654400912099162\n",
      "Epoch: 361, Loss: 0.6654327839865298\n",
      "Epoch: 362, Loss: 0.6654255096620377\n",
      "Epoch: 363, Loss: 0.6654182679805447\n",
      "Epoch: 364, Loss: 0.6654110586896478\n",
      "Epoch: 365, Loss: 0.6654038815403728\n",
      "Epoch: 366, Loss: 0.6653967362871147\n",
      "Epoch: 367, Loss: 0.6653896226875782\n",
      "Epoch: 368, Loss: 0.6653825405027185\n",
      "Epoch: 369, Loss: 0.6653754894966847\n",
      "Epoch: 370, Loss: 0.6653684694367633\n",
      "Epoch: 371, Loss: 0.6653614800933233\n",
      "Epoch: 372, Loss: 0.6653545212397621\n",
      "Epoch: 373, Loss: 0.6653475926524521\n",
      "Epoch: 374, Loss: 0.6653406941106899\n",
      "Epoch: 375, Loss: 0.6653338253966435\n",
      "Epoch: 376, Loss: 0.6653269862953035\n",
      "Epoch: 377, Loss: 0.6653201765944343\n",
      "Epoch: 378, Loss: 0.6653133960845246\n",
      "Epoch: 379, Loss: 0.665306644558741\n",
      "Epoch: 380, Loss: 0.6652999218128823\n",
      "Epoch: 381, Loss: 0.6652932276453328\n",
      "Epoch: 382, Loss: 0.6652865618570184\n",
      "Epoch: 383, Loss: 0.6652799242513627\n",
      "Epoch: 384, Loss: 0.6652733146342442\n",
      "Epoch: 385, Loss: 0.6652667328139542\n",
      "Epoch: 386, Loss: 0.6652601786011552\n",
      "Epoch: 387, Loss: 0.6652536518088409\n",
      "Epoch: 388, Loss: 0.6652471522522959\n",
      "Epoch: 389, Loss: 0.6652406797490572\n",
      "Epoch: 390, Loss: 0.6652342341188756\n",
      "Epoch: 391, Loss: 0.6652278151836782\n",
      "Epoch: 392, Loss: 0.6652214227675318\n",
      "Epoch: 393, Loss: 0.6652150566966064\n",
      "Epoch: 394, Loss: 0.6652087167991404\n",
      "Epoch: 395, Loss: 0.665202402905405\n",
      "Epoch: 396, Loss: 0.6651961148476703\n",
      "Epoch: 397, Loss: 0.6651898524601723\n",
      "Epoch: 398, Loss: 0.6651836155790797\n",
      "Epoch: 399, Loss: 0.6651774040424614\n",
      "Epoch: 400, Loss: 0.6651712176902554\n",
      "Epoch: 401, Loss: 0.6651650563642375\n",
      "Epoch: 402, Loss: 0.6651589199079903\n",
      "Epoch: 403, Loss: 0.6651528081668745\n",
      "Epoch: 404, Loss: 0.6651467209879985\n",
      "Epoch: 405, Loss: 0.6651406582201906\n",
      "Epoch: 406, Loss: 0.6651346197139696\n",
      "Epoch: 407, Loss: 0.6651286053215176\n",
      "Epoch: 408, Loss: 0.6651226148966535\n",
      "Epoch: 409, Loss: 0.6651166482948051\n",
      "Epoch: 410, Loss: 0.6651107053729842\n",
      "Epoch: 411, Loss: 0.6651047859897594\n",
      "Epoch: 412, Loss: 0.6650988900052321\n",
      "Epoch: 413, Loss: 0.6650930172810114\n",
      "Epoch: 414, Loss: 0.6650871676801895\n",
      "Epoch: 415, Loss: 0.6650813410673184\n",
      "Epoch: 416, Loss: 0.6650755373083856\n",
      "Epoch: 417, Loss: 0.6650697562707926\n",
      "Epoch: 418, Loss: 0.6650639978233306\n",
      "Epoch: 419, Loss: 0.6650582618361598\n",
      "Epoch: 420, Loss: 0.6650525481807866\n",
      "Epoch: 421, Loss: 0.6650468567300438\n",
      "Epoch: 422, Loss: 0.6650411873580675\n",
      "Epoch: 423, Loss: 0.6650355399402786\n",
      "Epoch: 424, Loss: 0.6650299143533616\n",
      "Epoch: 425, Loss: 0.6650243104752449\n",
      "Epoch: 426, Loss: 0.6650187281850815\n",
      "Epoch: 427, Loss: 0.6650131673632299\n",
      "Epoch: 428, Loss: 0.6650076278912357\n",
      "Epoch: 429, Loss: 0.6650021096518128\n",
      "Epoch: 430, Loss: 0.6649966125288252\n",
      "Epoch: 431, Loss: 0.6649911364072706\n",
      "Epoch: 432, Loss: 0.6649856811732605\n",
      "Epoch: 433, Loss: 0.6649802467140059\n",
      "Epoch: 434, Loss: 0.664974832917799\n",
      "Epoch: 435, Loss: 0.6649694396739969\n",
      "Epoch: 436, Loss: 0.6649640668730057\n",
      "Epoch: 437, Loss: 0.6649587144062646\n",
      "Epoch: 438, Loss: 0.6649533821662306\n",
      "Epoch: 439, Loss: 0.6649480700463622\n",
      "Epoch: 440, Loss: 0.664942777941106\n",
      "Epoch: 441, Loss: 0.6649375057458805\n",
      "Epoch: 442, Loss: 0.6649322533570625\n",
      "Epoch: 443, Loss: 0.6649270206719727\n",
      "Epoch: 444, Loss: 0.6649218075888614\n",
      "Epoch: 445, Loss: 0.6649166140068955\n",
      "Epoch: 446, Loss: 0.6649114398261443\n",
      "Epoch: 447, Loss: 0.6649062849475665\n",
      "Epoch: 448, Loss: 0.6649011492729978\n",
      "Epoch: 449, Loss: 0.6648960327051379\n",
      "Epoch: 450, Loss: 0.6648909351475372\n",
      "Epoch: 451, Loss: 0.6648858565045854\n",
      "Epoch: 452, Loss: 0.6648807966814995\n",
      "Epoch: 453, Loss: 0.6648757555843114\n",
      "Epoch: 454, Loss: 0.6648707331198564\n",
      "Epoch: 455, Loss: 0.6648657291957623\n",
      "Epoch: 456, Loss: 0.6648607437204372\n",
      "Epoch: 457, Loss: 0.6648557766030593\n",
      "Epoch: 458, Loss: 0.6648508277535662\n",
      "Epoch: 459, Loss: 0.6648458970826433\n",
      "Epoch: 460, Loss: 0.6648409845017141\n",
      "Epoch: 461, Loss: 0.66483608992293\n",
      "Epoch: 462, Loss: 0.6648312132591597\n",
      "Epoch: 463, Loss: 0.6648263544239797\n",
      "Epoch: 464, Loss: 0.6648215133316647\n",
      "Epoch: 465, Loss: 0.6648166898971773\n",
      "Epoch: 466, Loss: 0.6648118840361595\n",
      "Epoch: 467, Loss: 0.6648070956649231\n",
      "Epoch: 468, Loss: 0.6648023247004402\n",
      "Epoch: 469, Loss: 0.6647975710603354\n",
      "Epoch: 470, Loss: 0.6647928346628759\n",
      "Epoch: 471, Loss: 0.6647881154269633\n",
      "Epoch: 472, Loss: 0.6647834132721258\n",
      "Epoch: 473, Loss: 0.6647787281185087\n",
      "Epoch: 474, Loss: 0.6647740598868672\n",
      "Epoch: 475, Loss: 0.6647694084985581\n",
      "Epoch: 476, Loss: 0.6647647738755318\n",
      "Epoch: 477, Loss: 0.6647601559403248\n",
      "Epoch: 478, Loss: 0.664755554616052\n",
      "Epoch: 479, Loss: 0.6647509698263985\n",
      "Epoch: 480, Loss: 0.6647464014956141\n",
      "Epoch: 481, Loss: 0.6647418495485037\n",
      "Epoch: 482, Loss: 0.6647373139104226\n",
      "Epoch: 483, Loss: 0.6647327945072674\n",
      "Epoch: 484, Loss: 0.6647282912654707\n",
      "Epoch: 485, Loss: 0.6647238041119932\n",
      "Epoch: 486, Loss: 0.6647193329743184\n",
      "Epoch: 487, Loss: 0.6647148777804447\n",
      "Epoch: 488, Loss: 0.6647104384588796\n",
      "Epoch: 489, Loss: 0.6647060149386342\n",
      "Epoch: 490, Loss: 0.6647016071492151\n",
      "Epoch: 491, Loss: 0.6646972150206206\n",
      "Epoch: 492, Loss: 0.6646928384833328\n",
      "Epoch: 493, Loss: 0.664688477468313\n",
      "Epoch: 494, Loss: 0.6646841319069949\n",
      "Epoch: 495, Loss: 0.6646798017312804\n",
      "Epoch: 496, Loss: 0.6646754868735316\n",
      "Epoch: 497, Loss: 0.6646711872665686\n",
      "Epoch: 498, Loss: 0.6646669028436604\n",
      "Epoch: 499, Loss: 0.6646626335385231\n",
      "Epoch: 500, Loss: 0.6646583792853119\n",
      "Epoch: 501, Loss: 0.6646541400186176\n",
      "Epoch: 502, Loss: 0.6646499156734609\n",
      "Epoch: 503, Loss: 0.6646457061852875\n",
      "Epoch: 504, Loss: 0.6646415114899635\n",
      "Epoch: 505, Loss: 0.6646373315237707\n",
      "Epoch: 506, Loss: 0.6646331662234002\n",
      "Epoch: 507, Loss: 0.6646290155259506\n",
      "Epoch: 508, Loss: 0.6646248793689212\n",
      "Epoch: 509, Loss: 0.6646207576902083\n",
      "Epoch: 510, Loss: 0.6646166504281006\n",
      "Epoch: 511, Loss: 0.6646125575212751\n",
      "Epoch: 512, Loss: 0.6646084789087925\n",
      "Epoch: 513, Loss: 0.6646044145300932\n",
      "Epoch: 514, Loss: 0.6646003643249931\n",
      "Epoch: 515, Loss: 0.6645963282336794\n",
      "Epoch: 516, Loss: 0.6645923061967068\n",
      "Epoch: 517, Loss: 0.6645882981549928\n",
      "Epoch: 518, Loss: 0.6645843040498154\n",
      "Epoch: 519, Loss: 0.6645803238228076\n",
      "Epoch: 520, Loss: 0.6645763574159544\n",
      "Epoch: 521, Loss: 0.6645724047715893\n",
      "Epoch: 522, Loss: 0.66456846583239\n",
      "Epoch: 523, Loss: 0.6645645405413756\n",
      "Epoch: 524, Loss: 0.6645606288419019\n",
      "Epoch: 525, Loss: 0.6645567306776595\n",
      "Epoch: 526, Loss: 0.6645528459926686\n",
      "Epoch: 527, Loss: 0.6645489747312775\n",
      "Epoch: 528, Loss: 0.6645451168381575\n",
      "Epoch: 529, Loss: 0.664541272258301\n",
      "Epoch: 530, Loss: 0.6645374409370172\n",
      "Epoch: 531, Loss: 0.6645336228199298\n",
      "Epoch: 532, Loss: 0.6645298178529735\n",
      "Epoch: 533, Loss: 0.664526025982391\n",
      "Epoch: 534, Loss: 0.6645222471547295\n",
      "Epoch: 535, Loss: 0.6645184813168388\n",
      "Epoch: 536, Loss: 0.664514728415867\n",
      "Epoch: 537, Loss: 0.6645109883992588\n",
      "Epoch: 538, Loss: 0.6645072612147519\n",
      "Epoch: 539, Loss: 0.6645035468103744\n",
      "Epoch: 540, Loss: 0.6644998451344425\n",
      "Epoch: 541, Loss: 0.6644961561355568\n",
      "Epoch: 542, Loss: 0.6644924797626007\n",
      "Epoch: 543, Loss: 0.6644888159647365\n",
      "Epoch: 544, Loss: 0.6644851646914044\n",
      "Epoch: 545, Loss: 0.6644815258923186\n",
      "Epoch: 546, Loss: 0.664477899517465\n",
      "Epoch: 547, Loss: 0.6644742855170995\n",
      "Epoch: 548, Loss: 0.6644706838417445\n",
      "Epoch: 549, Loss: 0.6644670944421872\n",
      "Epoch: 550, Loss: 0.6644635172694767\n",
      "Epoch: 551, Loss: 0.6644599522749225\n",
      "Epoch: 552, Loss: 0.664456399410091\n",
      "Epoch: 553, Loss: 0.6644528586268044\n",
      "Epoch: 554, Loss: 0.664449329877137\n",
      "Epoch: 555, Loss: 0.6644458131134151\n",
      "Epoch: 556, Loss: 0.6644423082882122\n",
      "Epoch: 557, Loss: 0.6644388153543493\n",
      "Epoch: 558, Loss: 0.6644353342648914\n",
      "Epoch: 559, Loss: 0.6644318649731453\n",
      "Epoch: 560, Loss: 0.6644284074326583\n",
      "Epoch: 561, Loss: 0.6644249615972158\n",
      "Epoch: 562, Loss: 0.6644215274208389\n",
      "Epoch: 563, Loss: 0.6644181048577834\n",
      "Epoch: 564, Loss: 0.6644146938625367\n",
      "Epoch: 565, Loss: 0.6644112943898166\n",
      "Epoch: 566, Loss: 0.6644079063945695\n",
      "Epoch: 567, Loss: 0.6644045298319675\n",
      "Epoch: 568, Loss: 0.6644011646574083\n",
      "Epoch: 569, Loss: 0.6643978108265114\n",
      "Epoch: 570, Loss: 0.6643944682951178\n",
      "Epoch: 571, Loss: 0.6643911370192878\n",
      "Epoch: 572, Loss: 0.6643878169552986\n",
      "Epoch: 573, Loss: 0.6643845080596437\n",
      "Epoch: 574, Loss: 0.66438121028903\n",
      "Epoch: 575, Loss: 0.6643779236003771\n",
      "Epoch: 576, Loss: 0.6643746479508152\n",
      "Epoch: 577, Loss: 0.6643713832976836\n",
      "Epoch: 578, Loss: 0.6643681295985288\n",
      "Epoch: 579, Loss: 0.6643648868111031\n",
      "Epoch: 580, Loss: 0.6643616548933633\n",
      "Epoch: 581, Loss: 0.6643584338034683\n",
      "Epoch: 582, Loss: 0.6643552234997787\n",
      "Epoch: 583, Loss: 0.6643520239408546\n",
      "Epoch: 584, Loss: 0.664348835085454\n",
      "Epoch: 585, Loss: 0.6643456568925314\n",
      "Epoch: 586, Loss: 0.6643424893212371\n",
      "Epoch: 587, Loss: 0.6643393323309144\n",
      "Epoch: 588, Loss: 0.6643361858810996\n",
      "Epoch: 589, Loss: 0.6643330499315192\n",
      "Epoch: 590, Loss: 0.6643299244420896\n",
      "Epoch: 591, Loss: 0.6643268093729158\n",
      "Epoch: 592, Loss: 0.6643237046842886\n",
      "Epoch: 593, Loss: 0.6643206103366848\n",
      "Epoch: 594, Loss: 0.6643175262907653\n",
      "Epoch: 595, Loss: 0.6643144525073739\n",
      "Epoch: 596, Loss: 0.6643113889475358\n",
      "Epoch: 597, Loss: 0.6643083355724564\n",
      "Epoch: 598, Loss: 0.6643052923435202\n",
      "Epoch: 599, Loss: 0.6643022592222895\n",
      "Epoch: 600, Loss: 0.664299236170503\n",
      "Epoch: 601, Loss: 0.6642962231500747\n",
      "Epoch: 602, Loss: 0.664293220123093\n",
      "Epoch: 603, Loss: 0.6642902270518188\n",
      "Epoch: 604, Loss: 0.6642872438986851\n",
      "Epoch: 605, Loss: 0.664284270626295\n",
      "Epoch: 606, Loss: 0.664281307197422\n",
      "Epoch: 607, Loss: 0.6642783535750066\n",
      "Epoch: 608, Loss: 0.6642754097221578\n",
      "Epoch: 609, Loss: 0.6642724756021495\n",
      "Epoch: 610, Loss: 0.6642695511784216\n",
      "Epoch: 611, Loss: 0.6642666364145774\n",
      "Epoch: 612, Loss: 0.6642637312743829\n",
      "Epoch: 613, Loss: 0.6642608357217661\n",
      "Epoch: 614, Loss: 0.664257949720816\n",
      "Epoch: 615, Loss: 0.6642550732357805\n",
      "Epoch: 616, Loss: 0.6642522062310672\n",
      "Epoch: 617, Loss: 0.6642493486712405\n",
      "Epoch: 618, Loss: 0.664246500521022\n",
      "Epoch: 619, Loss: 0.6642436617452886\n",
      "Epoch: 620, Loss: 0.664240832309072\n",
      "Epoch: 621, Loss: 0.6642380121775578\n",
      "Epoch: 622, Loss: 0.6642352013160844\n",
      "Epoch: 623, Loss: 0.6642323996901415\n",
      "Epoch: 624, Loss: 0.6642296072653701\n",
      "Epoch: 625, Loss: 0.6642268240075611\n",
      "Epoch: 626, Loss: 0.6642240498826542\n",
      "Epoch: 627, Loss: 0.6642212848567376\n",
      "Epoch: 628, Loss: 0.6642185288960465\n",
      "Epoch: 629, Loss: 0.6642157819669622\n",
      "Epoch: 630, Loss: 0.6642130440360114\n",
      "Epoch: 631, Loss: 0.6642103150698664\n",
      "Epoch: 632, Loss: 0.6642075950353417\n",
      "Epoch: 633, Loss: 0.6642048838993955\n",
      "Epoch: 634, Loss: 0.6642021816291279\n",
      "Epoch: 635, Loss: 0.6641994881917801\n",
      "Epoch: 636, Loss: 0.6641968035547335\n",
      "Epoch: 637, Loss: 0.6641941276855093\n",
      "Epoch: 638, Loss: 0.664191460551767\n",
      "Epoch: 639, Loss: 0.6641888021213047\n",
      "Epoch: 640, Loss: 0.6641861523620562\n",
      "Epoch: 641, Loss: 0.6641835112420935\n",
      "Epoch: 642, Loss: 0.6641808787296223\n",
      "Epoch: 643, Loss: 0.664178254792984\n",
      "Epoch: 644, Loss: 0.664175639400654\n",
      "Epoch: 645, Loss: 0.6641730325212406\n",
      "Epoch: 646, Loss: 0.6641704341234846\n",
      "Epoch: 647, Loss: 0.6641678441762586\n",
      "Epoch: 648, Loss: 0.6641652626485662\n",
      "Epoch: 649, Loss: 0.6641626895095409\n",
      "Epoch: 650, Loss: 0.6641601247284464\n",
      "Epoch: 651, Loss: 0.6641575682746743\n",
      "Epoch: 652, Loss: 0.6641550201177451\n",
      "Epoch: 653, Loss: 0.664152480227306\n",
      "Epoch: 654, Loss: 0.6641499485731311\n",
      "Epoch: 655, Loss: 0.664147425125121\n",
      "Epoch: 656, Loss: 0.664144909853301\n",
      "Epoch: 657, Loss: 0.6641424027278207\n",
      "Epoch: 658, Loss: 0.6641399037189546\n",
      "Epoch: 659, Loss: 0.6641374127970997\n",
      "Epoch: 660, Loss: 0.6641349299327758\n",
      "Epoch: 661, Loss: 0.6641324550966244\n",
      "Epoch: 662, Loss: 0.6641299882594093\n",
      "Epoch: 663, Loss: 0.6641275293920135\n",
      "Epoch: 664, Loss: 0.6641250784654409\n",
      "Epoch: 665, Loss: 0.664122635450815\n",
      "Epoch: 666, Loss: 0.6641202003193768\n",
      "Epoch: 667, Loss: 0.6641177730424868\n",
      "Epoch: 668, Loss: 0.6641153535916221\n",
      "Epoch: 669, Loss: 0.6641129419383772\n",
      "Epoch: 670, Loss: 0.6641105380544624\n",
      "Epoch: 671, Loss: 0.664108141911704\n",
      "Epoch: 672, Loss: 0.6641057534820436\n",
      "Epoch: 673, Loss: 0.6641033727375364\n",
      "Epoch: 674, Loss: 0.6641009996503523\n",
      "Epoch: 675, Loss: 0.664098634192774\n",
      "Epoch: 676, Loss: 0.6640962763371975\n",
      "Epoch: 677, Loss: 0.6640939260561304\n",
      "Epoch: 678, Loss: 0.6640915833221919\n",
      "Epoch: 679, Loss: 0.6640892481081122\n",
      "Epoch: 680, Loss: 0.6640869203867327\n",
      "Epoch: 681, Loss: 0.6640846001310033\n",
      "Epoch: 682, Loss: 0.6640822873139844\n",
      "Epoch: 683, Loss: 0.664079981908845\n",
      "Epoch: 684, Loss: 0.6640776838888618\n",
      "Epoch: 685, Loss: 0.6640753932274193\n",
      "Epoch: 686, Loss: 0.6640731098980098\n",
      "Epoch: 687, Loss: 0.6640708338742316\n",
      "Epoch: 688, Loss: 0.6640685651297894\n",
      "Epoch: 689, Loss: 0.6640663036384932\n",
      "Epoch: 690, Loss: 0.6640640493742582\n",
      "Epoch: 691, Loss: 0.6640618023111047\n",
      "Epoch: 692, Loss: 0.6640595624231559\n",
      "Epoch: 693, Loss: 0.6640573296846394\n",
      "Epoch: 694, Loss: 0.6640551040698853\n",
      "Epoch: 695, Loss: 0.6640528855533271\n",
      "Epoch: 696, Loss: 0.664050674109499\n",
      "Epoch: 697, Loss: 0.6640484697130377\n",
      "Epoch: 698, Loss: 0.6640462723386805\n",
      "Epoch: 699, Loss: 0.6640440819612656\n",
      "Epoch: 700, Loss: 0.6640418985557308\n",
      "Epoch: 701, Loss: 0.6640397220971139\n",
      "Epoch: 702, Loss: 0.6640375525605515\n",
      "Epoch: 703, Loss: 0.6640353899212792\n",
      "Epoch: 704, Loss: 0.6640332341546302\n",
      "Epoch: 705, Loss: 0.6640310852360362\n",
      "Epoch: 706, Loss: 0.664028943141025\n",
      "Epoch: 707, Loss: 0.6640268078452225\n",
      "Epoch: 708, Loss: 0.6640246793243499\n",
      "Epoch: 709, Loss: 0.6640225575542248\n",
      "Epoch: 710, Loss: 0.6640204425107601\n",
      "Epoch: 711, Loss: 0.6640183341699633\n",
      "Epoch: 712, Loss: 0.6640162325079371\n",
      "Epoch: 713, Loss: 0.6640141375008777\n",
      "Epoch: 714, Loss: 0.6640120491250752\n",
      "Epoch: 715, Loss: 0.6640099673569131\n",
      "Epoch: 716, Loss: 0.6640078921728669\n",
      "Epoch: 717, Loss: 0.6640058235495055\n",
      "Epoch: 718, Loss: 0.664003761463489\n",
      "Epoch: 719, Loss: 0.6640017058915694\n",
      "Epoch: 720, Loss: 0.6639996568105894\n",
      "Epoch: 721, Loss: 0.6639976141974826\n",
      "Epoch: 722, Loss: 0.6639955780292727\n",
      "Epoch: 723, Loss: 0.6639935482830733\n",
      "Epoch: 724, Loss: 0.6639915249360876\n",
      "Epoch: 725, Loss: 0.6639895079656074\n",
      "Epoch: 726, Loss: 0.6639874973490136\n",
      "Epoch: 727, Loss: 0.6639854930637747\n",
      "Epoch: 728, Loss: 0.6639834950874475\n",
      "Epoch: 729, Loss: 0.663981503397676\n",
      "Epoch: 730, Loss: 0.6639795179721913\n",
      "Epoch: 731, Loss: 0.663977538788811\n",
      "Epoch: 732, Loss: 0.663975565825439\n",
      "Epoch: 733, Loss: 0.663973599060065\n",
      "Epoch: 734, Loss: 0.663971638470764\n",
      "Epoch: 735, Loss: 0.6639696840356966\n",
      "Epoch: 736, Loss: 0.6639677357331074\n",
      "Epoch: 737, Loss: 0.6639657935413257\n",
      "Epoch: 738, Loss: 0.6639638574387648\n",
      "Epoch: 739, Loss: 0.6639619274039212\n",
      "Epoch: 740, Loss: 0.663960003415375\n",
      "Epoch: 741, Loss: 0.6639580854517888\n",
      "Epoch: 742, Loss: 0.6639561734919079\n",
      "Epoch: 743, Loss: 0.6639542675145594\n",
      "Epoch: 744, Loss: 0.6639523674986525\n",
      "Epoch: 745, Loss: 0.6639504734231774\n",
      "Epoch: 746, Loss: 0.6639485852672053\n",
      "Epoch: 747, Loss: 0.6639467030098887\n",
      "Epoch: 748, Loss: 0.6639448266304594\n",
      "Epoch: 749, Loss: 0.6639429561082297\n",
      "Epoch: 750, Loss: 0.663941091422592\n",
      "Epoch: 751, Loss: 0.6639392325530167\n",
      "Epoch: 752, Loss: 0.663937379479054\n",
      "Epoch: 753, Loss: 0.6639355321803324\n",
      "Epoch: 754, Loss: 0.6639336906365589\n",
      "Epoch: 755, Loss: 0.6639318548275177\n",
      "Epoch: 756, Loss: 0.6639300247330714\n",
      "Epoch: 757, Loss: 0.6639282003331588\n",
      "Epoch: 758, Loss: 0.6639263816077966\n",
      "Epoch: 759, Loss: 0.6639245685370774\n",
      "Epoch: 760, Loss: 0.66392276110117\n",
      "Epoch: 761, Loss: 0.6639209592803192\n",
      "Epoch: 762, Loss: 0.6639191630548456\n",
      "Epoch: 763, Loss: 0.6639173724051446\n",
      "Epoch: 764, Loss: 0.6639155873116865\n",
      "Epoch: 765, Loss: 0.6639138077550165\n",
      "Epoch: 766, Loss: 0.6639120337157542\n",
      "Epoch: 767, Loss: 0.6639102651745922\n",
      "Epoch: 768, Loss: 0.6639085021122979\n",
      "Epoch: 769, Loss: 0.6639067445097112\n",
      "Epoch: 770, Loss: 0.663904992347745\n",
      "Epoch: 771, Loss: 0.6639032456073856\n",
      "Epoch: 772, Loss: 0.6639015042696911\n",
      "Epoch: 773, Loss: 0.6638997683157913\n",
      "Epoch: 774, Loss: 0.6638980377268888\n",
      "Epoch: 775, Loss: 0.6638963124842568\n",
      "Epoch: 776, Loss: 0.66389459256924\n",
      "Epoch: 777, Loss: 0.6638928779632536\n",
      "Epoch: 778, Loss: 0.663891168647784\n",
      "Epoch: 779, Loss: 0.6638894646043872\n",
      "Epoch: 780, Loss: 0.6638877658146894\n",
      "Epoch: 781, Loss: 0.663886072260387\n",
      "Epoch: 782, Loss: 0.6638843839232446\n",
      "Epoch: 783, Loss: 0.6638827007850967\n",
      "Epoch: 784, Loss: 0.6638810228278466\n",
      "Epoch: 785, Loss: 0.6638793500334658\n",
      "Epoch: 786, Loss: 0.6638776823839939\n",
      "Epoch: 787, Loss: 0.6638760198615389\n",
      "Epoch: 788, Loss: 0.6638743624482761\n",
      "Epoch: 789, Loss: 0.6638727101264483\n",
      "Epoch: 790, Loss: 0.6638710628783651\n",
      "Epoch: 791, Loss: 0.6638694206864031\n",
      "Epoch: 792, Loss: 0.6638677835330057\n",
      "Epoch: 793, Loss: 0.663866151400682\n",
      "Epoch: 794, Loss: 0.663864524272007\n",
      "Epoch: 795, Loss: 0.6638629021296225\n",
      "Epoch: 796, Loss: 0.6638612849562343\n",
      "Epoch: 797, Loss: 0.663859672734614\n",
      "Epoch: 798, Loss: 0.6638580654475982\n",
      "Epoch: 799, Loss: 0.6638564630780878\n",
      "Epoch: 800, Loss: 0.6638548656090482\n",
      "Epoch: 801, Loss: 0.6638532730235087\n",
      "Epoch: 802, Loss: 0.6638516853045628\n",
      "Epoch: 803, Loss: 0.6638501024353672\n",
      "Epoch: 804, Loss: 0.6638485243991419\n",
      "Epoch: 805, Loss: 0.6638469511791697\n",
      "Epoch: 806, Loss: 0.6638453827587971\n",
      "Epoch: 807, Loss: 0.6638438191214319\n",
      "Epoch: 808, Loss: 0.6638422602505447\n",
      "Epoch: 809, Loss: 0.6638407061296685\n",
      "Epoch: 810, Loss: 0.6638391567423971\n",
      "Epoch: 811, Loss: 0.6638376120723868\n",
      "Epoch: 812, Loss: 0.6638360721033539\n",
      "Epoch: 813, Loss: 0.6638345368190771\n",
      "Epoch: 814, Loss: 0.6638330062033947\n",
      "Epoch: 815, Loss: 0.663831480240206\n",
      "Epoch: 816, Loss: 0.6638299589134706\n",
      "Epoch: 817, Loss: 0.6638284422072076\n",
      "Epoch: 818, Loss: 0.6638269301054966\n",
      "Epoch: 819, Loss: 0.6638254225924757\n",
      "Epoch: 820, Loss: 0.6638239196523431\n",
      "Epoch: 821, Loss: 0.663822421269356\n",
      "Epoch: 822, Loss: 0.6638209274278295\n",
      "Epoch: 823, Loss: 0.6638194381121384\n",
      "Epoch: 824, Loss: 0.6638179533067148\n",
      "Epoch: 825, Loss: 0.6638164729960495\n",
      "Epoch: 826, Loss: 0.663814997164691\n",
      "Epoch: 827, Loss: 0.6638135257972451\n",
      "Epoch: 828, Loss: 0.6638120588783752\n",
      "Epoch: 829, Loss: 0.6638105963928019\n",
      "Epoch: 830, Loss: 0.6638091383253027\n",
      "Epoch: 831, Loss: 0.6638076846607113\n",
      "Epoch: 832, Loss: 0.6638062353839184\n",
      "Epoch: 833, Loss: 0.6638047904798706\n",
      "Epoch: 834, Loss: 0.6638033499335707\n",
      "Epoch: 835, Loss: 0.6638019137300768\n",
      "Epoch: 836, Loss: 0.6638004818545031\n",
      "Epoch: 837, Loss: 0.6637990542920188\n",
      "Epoch: 838, Loss: 0.6637976310278486\n",
      "Epoch: 839, Loss: 0.6637962120472709\n",
      "Epoch: 840, Loss: 0.6637947973356202\n",
      "Epoch: 841, Loss: 0.6637933868782844\n",
      "Epoch: 842, Loss: 0.6637919806607061\n",
      "Epoch: 843, Loss: 0.6637905786683818\n",
      "Epoch: 844, Loss: 0.6637891808868615\n",
      "Epoch: 845, Loss: 0.6637877873017491\n",
      "Epoch: 846, Loss: 0.6637863978987019\n",
      "Epoch: 847, Loss: 0.6637850126634298\n",
      "Epoch: 848, Loss: 0.6637836315816958\n",
      "Epoch: 849, Loss: 0.6637822546393164\n",
      "Epoch: 850, Loss: 0.6637808818221593\n",
      "Epoch: 851, Loss: 0.6637795131161452\n",
      "Epoch: 852, Loss: 0.6637781485072471\n",
      "Epoch: 853, Loss: 0.6637767879814892\n",
      "Epoch: 854, Loss: 0.6637754315249479\n",
      "Epoch: 855, Loss: 0.6637740791237506\n",
      "Epoch: 856, Loss: 0.6637727307640765\n",
      "Epoch: 857, Loss: 0.6637713864321553\n",
      "Epoch: 858, Loss: 0.6637700461142676\n",
      "Epoch: 859, Loss: 0.6637687097967452\n",
      "Epoch: 860, Loss: 0.6637673774659697\n",
      "Epoch: 861, Loss: 0.6637660491083732\n",
      "Epoch: 862, Loss: 0.6637647247104378\n",
      "Epoch: 863, Loss: 0.6637634042586956\n",
      "Epoch: 864, Loss: 0.6637620877397279\n",
      "Epoch: 865, Loss: 0.663760775140166\n",
      "Epoch: 866, Loss: 0.6637594664466897\n",
      "Epoch: 867, Loss: 0.6637581616460287\n",
      "Epoch: 868, Loss: 0.6637568607249612\n",
      "Epoch: 869, Loss: 0.6637555636703137\n",
      "Epoch: 870, Loss: 0.6637542704689618\n",
      "Epoch: 871, Loss: 0.6637529811078288\n",
      "Epoch: 872, Loss: 0.6637516955738866\n",
      "Epoch: 873, Loss: 0.6637504138541545\n",
      "Epoch: 874, Loss: 0.6637491359357001\n",
      "Epoch: 875, Loss: 0.6637478618056378\n",
      "Epoch: 876, Loss: 0.66374659145113\n",
      "Epoch: 877, Loss: 0.6637453248593859\n",
      "Epoch: 878, Loss: 0.6637440620176615\n",
      "Epoch: 879, Loss: 0.6637428029132602\n",
      "Epoch: 880, Loss: 0.6637415475335311\n",
      "Epoch: 881, Loss: 0.6637402958658705\n",
      "Epoch: 882, Loss: 0.6637390478977204\n",
      "Epoch: 883, Loss: 0.6637378036165694\n",
      "Epoch: 884, Loss: 0.6637365630099512\n",
      "Epoch: 885, Loss: 0.6637353260654456\n",
      "Epoch: 886, Loss: 0.6637340927706785\n",
      "Epoch: 887, Loss: 0.6637328631133198\n",
      "Epoch: 888, Loss: 0.6637316370810855\n",
      "Epoch: 889, Loss: 0.6637304146617363\n",
      "Epoch: 890, Loss: 0.6637291958430781\n",
      "Epoch: 891, Loss: 0.6637279806129605\n",
      "Epoch: 892, Loss: 0.6637267689592782\n",
      "Epoch: 893, Loss: 0.6637255608699703\n",
      "Epoch: 894, Loss: 0.6637243563330195\n",
      "Epoch: 895, Loss: 0.6637231553364527\n",
      "Epoch: 896, Loss: 0.6637219578683404\n",
      "Epoch: 897, Loss: 0.6637207639167971\n",
      "Epoch: 898, Loss: 0.6637195734699799\n",
      "Epoch: 899, Loss: 0.6637183865160902\n",
      "Epoch: 900, Loss: 0.6637172030433715\n",
      "Epoch: 901, Loss: 0.6637160230401107\n",
      "Epoch: 902, Loss: 0.6637148464946372\n",
      "Epoch: 903, Loss: 0.6637136733953235\n",
      "Epoch: 904, Loss: 0.6637125037305835\n",
      "Epoch: 905, Loss: 0.6637113374888743\n",
      "Epoch: 906, Loss: 0.663710174658695\n",
      "Epoch: 907, Loss: 0.6637090152285857\n",
      "Epoch: 908, Loss: 0.663707859187129\n",
      "Epoch: 909, Loss: 0.6637067065229493\n",
      "Epoch: 910, Loss: 0.6637055572247117\n",
      "Epoch: 911, Loss: 0.6637044112811229\n",
      "Epoch: 912, Loss: 0.6637032686809309\n",
      "Epoch: 913, Loss: 0.6637021294129244\n",
      "Epoch: 914, Loss: 0.6637009934659329\n",
      "Epoch: 915, Loss: 0.6636998608288266\n",
      "Epoch: 916, Loss: 0.663698731490516\n",
      "Epoch: 917, Loss: 0.6636976054399519\n",
      "Epoch: 918, Loss: 0.6636964826661257\n",
      "Epoch: 919, Loss: 0.6636953631580682\n",
      "Epoch: 920, Loss: 0.6636942469048506\n",
      "Epoch: 921, Loss: 0.663693133895583\n",
      "Epoch: 922, Loss: 0.663692024119416\n",
      "Epoch: 923, Loss: 0.6636909175655388\n",
      "Epoch: 924, Loss: 0.6636898142231802\n",
      "Epoch: 925, Loss: 0.6636887140816078\n",
      "Epoch: 926, Loss: 0.6636876171301287\n",
      "Epoch: 927, Loss: 0.6636865233580879\n",
      "Epoch: 928, Loss: 0.6636854327548698\n",
      "Epoch: 929, Loss: 0.663684345309897\n",
      "Epoch: 930, Loss: 0.6636832610126304\n",
      "Epoch: 931, Loss: 0.6636821798525687\n",
      "Epoch: 932, Loss: 0.6636811018192496\n",
      "Epoch: 933, Loss: 0.6636800269022477\n",
      "Epoch: 934, Loss: 0.6636789550911756\n",
      "Epoch: 935, Loss: 0.6636778863756841\n",
      "Epoch: 936, Loss: 0.6636768207454602\n",
      "Epoch: 937, Loss: 0.6636757581902296\n",
      "Epoch: 938, Loss: 0.6636746986997544\n",
      "Epoch: 939, Loss: 0.6636736422638335\n",
      "Epoch: 940, Loss: 0.6636725888723032\n",
      "Epoch: 941, Loss: 0.6636715385150365\n",
      "Epoch: 942, Loss: 0.6636704911819423\n",
      "Epoch: 943, Loss: 0.6636694468629669\n",
      "Epoch: 944, Loss: 0.6636684055480921\n",
      "Epoch: 945, Loss: 0.6636673672273365\n",
      "Epoch: 946, Loss: 0.6636663318907544\n",
      "Epoch: 947, Loss: 0.6636652995284362\n",
      "Epoch: 948, Loss: 0.6636642701305074\n",
      "Epoch: 949, Loss: 0.66366324368713\n",
      "Epoch: 950, Loss: 0.6636622201885009\n",
      "Epoch: 951, Loss: 0.6636611996248526\n",
      "Epoch: 952, Loss: 0.6636601819864526\n",
      "Epoch: 953, Loss: 0.6636591672636037\n",
      "Epoch: 954, Loss: 0.6636581554466436\n",
      "Epoch: 955, Loss: 0.6636571465259447\n",
      "Epoch: 956, Loss: 0.6636561404919137\n",
      "Epoch: 957, Loss: 0.6636551373349927\n",
      "Epoch: 958, Loss: 0.6636541370456577\n",
      "Epoch: 959, Loss: 0.6636531396144187\n",
      "Epoch: 960, Loss: 0.6636521450318205\n",
      "Epoch: 961, Loss: 0.6636511532884414\n",
      "Epoch: 962, Loss: 0.6636501643748935\n",
      "Epoch: 963, Loss: 0.6636491782818232\n",
      "Epoch: 964, Loss: 0.6636481949999099\n",
      "Epoch: 965, Loss: 0.6636472145198671\n",
      "Epoch: 966, Loss: 0.6636462368324414\n",
      "Epoch: 967, Loss: 0.6636452619284122\n",
      "Epoch: 968, Loss: 0.6636442897985927\n",
      "Epoch: 969, Loss: 0.6636433204338287\n",
      "Epoch: 970, Loss: 0.6636423538249988\n",
      "Epoch: 971, Loss: 0.6636413899630147\n",
      "Epoch: 972, Loss: 0.6636404288388202\n",
      "Epoch: 973, Loss: 0.6636394704433922\n",
      "Epoch: 974, Loss: 0.6636385147677394\n",
      "Epoch: 975, Loss: 0.663637561802903\n",
      "Epoch: 976, Loss: 0.663636611539956\n",
      "Epoch: 977, Loss: 0.6636356639700041\n",
      "Epoch: 978, Loss: 0.6636347190841841\n",
      "Epoch: 979, Loss: 0.663633776873665\n",
      "Epoch: 980, Loss: 0.6636328373296473\n",
      "Epoch: 981, Loss: 0.6636319004433627\n",
      "Epoch: 982, Loss: 0.663630966206075\n",
      "Epoch: 983, Loss: 0.6636300346090785\n",
      "Epoch: 984, Loss: 0.6636291056436993\n",
      "Epoch: 985, Loss: 0.663628179301294\n",
      "Epoch: 986, Loss: 0.6636272555732501\n",
      "Epoch: 987, Loss: 0.6636263344509865\n",
      "Epoch: 988, Loss: 0.6636254159259524\n",
      "Epoch: 989, Loss: 0.6636244999896271\n",
      "Epoch: 990, Loss: 0.6636235866335213\n",
      "Epoch: 991, Loss: 0.6636226758491752\n",
      "Epoch: 992, Loss: 0.6636217676281597\n",
      "Epoch: 993, Loss: 0.6636208619620755\n",
      "Epoch: 994, Loss: 0.6636199588425533\n",
      "Epoch: 995, Loss: 0.6636190582612541\n",
      "Epoch: 996, Loss: 0.6636181602098681\n",
      "Epoch: 997, Loss: 0.6636172646801155\n",
      "Epoch: 998, Loss: 0.6636163716637458\n",
      "Epoch: 999, Loss: 0.6636154811525381\n",
      "Epoch: 1000, Loss: 0.6636145931383005\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(x_train_tensor)\n",
    "\n",
    "# Define loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward Pass\n",
    "    y_pred = model.forward(x_train_tensor)\n",
    "\n",
    "    # Loss Calculation\n",
    "    loss = model.loss_function(y_pred, y_train_tensor)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Backward Pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Paramers Update\n",
    "    with torch.no_grad():\n",
    "        model.weights -= lr * model.weights.grad\n",
    "        model.bias -= lr * model.bias.grad\n",
    "    \n",
    "    # Zero Gradients\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383a264",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94a4ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6491228342056274\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(x_test_tensor)\n",
    "    y_pred = (y_pred > 0.7).float()\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f\"Accuracy: {accuracy.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
